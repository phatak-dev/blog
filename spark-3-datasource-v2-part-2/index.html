<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Data Source V2 API in Spark 3.0 - Part 2 : Anatomy of V2 Read API</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="http://blog.madhukaraphatak.com/spark-3-datasource-v2-part-2">
     <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Data Source V2 API in Spark 3.0 - Part 2 : Anatomy of V2 Read API</h1>
  <p class="meta">Mar 24, 2020</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/spark-three"><span class="category">spark-three</span></a>
    
    <a href="/categories/datasource-v2-spark-three"><span class="category">datasource-v2-spark-three</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>Spark 3.0 is a major release of Apache Spark framework. It’s been in preview from last December and going to have  a stable release very soon. As part of major release, Spark has a habit of shaking up API’s to bring it to latest standards. There will be breaking changes also in these API’s. One of such API is Data source V2 API.</p>

<p>Data Source V2 API, a new data source API for spark, was introduced in spark 2.3. Then it’s been updated in spark 2.4. I have written detailed posts on same <a href="/categories/datasource-v2-series">here</a>.</p>

<p>This API is going to be completely changed in Spark 3.0. Spark rarely change an API this frequently in between releases. But as data source are heart of the framework, they are improved constantly. Also in spark 2.4, these API’s were marked <strong>evolving</strong>. This means they are meant to be changed in future.</p>

<p>The usage of the data sources have not changed in 3.0. So if you are a user of the third party data sources you don’t need to worry. These changes are geared mainly towards the developer of these sources. Also all the sources written V1 API going to work even in 3.0. So if your source is not updated, no need to panic. It’s going to work without latest optimisations.</p>

<p>These new changes in V2 API brings more control to data source developer and better integration with spark optimiser. Moving to this API makes third party sources more performant. So in these series of posts I will be discussing the new Data source V2 API in 3.0.</p>

<p>This is the second post in the series where we discuss about different interfaces to read data in V2 API.You can read all the posts in the series <a href="/categories/datasource-v2-spark-three">here</a>.</p>

<h2 id="java-interfaces">Java Interfaces</h2>

<p>One of the characteristics of V2 API’s is it’s exposed in terms of Java interfaces rather than scala traits. The primary reason for this is better interop with Java.</p>

<p>The below are the basic interfaces to read the data in V2 API.</p>

<h2 id="tableprovider">TableProvider</h2>

<p>TableProvider trait signifies it’s a source which can read or write a table. Here table is a structured dataset. The below are the methods</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">inferSchema</span><span class="o">(</span><span class="n">caseInsensitiveStringMap</span><span class="k">:</span> <span class="kt">CaseInsensitiveStringMap</span><span class="o">)</span><span class="k">:</span> <span class="kt">StructType</span>

<span class="k">def</span> <span class="n">getTable</span><span class="o">(</span><span class="n">structType</span><span class="k">:</span> <span class="kt">StructType</span><span class="o">,</span> <span class="n">transforms</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Transform</span><span class="o">],</span> <span class="n">map</span><span class="k">:</span> <span class="kt">util.Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">])</span></code></pre></div>

<p>The methods are</p>

<ul>
  <li>
    <p>inferSchema - The method takes parameter from user and tries to infer the schema</p>
  </li>
  <li>
    <p>getTable - This is used for loading table with user specified schema and other transformations.</p>
  </li>
</ul>

<h2 id="table">Table</h2>

<p>Table is an interface representing a logical structured data set of a data source. It exposes below three methods</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">name</span><span class="k">:</span><span class="kt">String</span>

<span class="k">def</span> <span class="n">schema</span><span class="k">:</span><span class="kt">StructType</span>

<span class="k">def</span> <span class="n">capabilities</span><span class="k">:</span> <span class="kt">TableCapability</span></code></pre></div>

<p>The different methods are</p>

<ul>
  <li>
    <p>name : A name to identify the table.</p>
  </li>
  <li>
    <p>schema : Table Schema. An empty schema can be returned if schema inference needed.</p>
  </li>
  <li>
    <p>capabilities : Capabilities exposed by the table. This is one of the unique feature added in spark 3.0. This allows to specifying what kind of operation table supports. Some capabilities like BATCH_READ, BATCH_WRITE. This helps spark to verify these before attempting to run the operations.</p>
  </li>
</ul>

<h2 id="supportsread">SupportsRead</h2>

<p>This interface indicates that source supports read. This has one abstract method that needs to be overridden.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">newScanBuilder</span><span class="o">(</span><span class="n">options</span><span class="k">:</span> <span class="kt">CaseInsensitiveStringMap</span><span class="o">)</span><span class="k">:</span> <span class="kt">ScanBuilder</span></code></pre></div>

<h2 id="scanbuilder">ScanBuilder</h2>

<p>An interface for building <strong>Scan</strong>. This interface can mix with filter push down to keep the needed information to push the filters to readers. The exposed abstract methods are</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">build</span><span class="o">()</span><span class="k">:</span> <span class="kt">Scan</span></code></pre></div>

<h2 id="scan">Scan</h2>

<p>Logical representation of a data source scan. This interface is used to provide logical information, like what the actual read schema is. This is a common scan for all different scanning like batch, micro batch etc. The needed methods to be overridden are</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">readSchema</span><span class="o">()</span><span class="k">:</span> <span class="kt">StructType</span>

 <span class="k">def</span> <span class="n">toBatch</span><span class="k">:</span> <span class="kt">Batch</span></code></pre></div>

<p>The methods are</p>

<ul>
  <li>
    <p>readSchema - The actual schema of the source. This may look like repetitive from Table interface. The reason it is repeated because, after column pruning or other optimisation the schema may change or we may need inference of schema. This method returns actual schema of the data where as the Table one returns the initial schema.</p>
  </li>
  <li>
    <p>toBatch - This method needs to be overridden to indicate that this scan configuration should be used for batch reading.</p>
  </li>
</ul>

<h2 id="batch">Batch</h2>

<p>A physical representation of a data source scan for batch queries. This interface is used to provide physical information, like how many partitions the scanned data has, and how to read records from the partitions.</p>

<p>The methods that need to be overridden are</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">planInputPartitions</span><span class="o">()</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">InputPartition</span><span class="o">]</span> 

<span class="k">def</span> <span class="n">createReaderFactory</span><span class="o">()</span><span class="k">:</span> <span class="kt">PartitionReaderFactory</span></code></pre></div>

<p>The methods are</p>

<ul>
  <li>
    <p>planInputPartitions : List of partitions for the table. This number decides number of partitions in Dataset.</p>
  </li>
  <li>
    <p>createReaderFactory : Factory to create the readers</p>
  </li>
</ul>

<h2 id="partitionreaderfactory">PartitionReaderFactory</h2>

<p>It’s a factory class to create actual data readers. The data reader creation happens on the individual machines. It exposes single method.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">createReader</span><span class="o">(</span><span class="n">partition</span><span class="k">:</span> <span class="kt">InputPartition</span><span class="o">)</span><span class="k">:</span> <span class="kt">PartitionReader</span><span class="o">[</span><span class="kt">InternalRow</span><span class="o">]</span></code></pre></div>

<p>As the name suggest, it creates data reader.</p>

<h2 id="partitionreader">PartitionReader</h2>

<p>Finally we have the interface which actually reads the data. The below are methods</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">next</span> <span class="k">:</span> <span class="kt">Boolean</span>

<span class="k">def</span> <span class="n">get</span> <span class="k">:</span> <span class="kt">T</span>

<span class="k">def</span> <span class="n">close</span><span class="o">()</span> <span class="k">:</span> <span class="kt">Unit</span></code></pre></div>

<p>As you can see from interface, it looks as simple iterator based reader. Currently T can be only InternalRow.</p>

<h2 id="references">References</h2>

<p><a href="https://github.com/apache/spark/pull/22009">https://github.com/apache/spark/pull/22009</a></p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post we discussed some of the important interfaces from data source V2 API for reading data. You can see how this API is much different than earlier API.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">01 Apr 2020</span>
     &raquo; <a href="/spark-3-datasource-v2-part-5">Data Source V2 API in Spark 3.0 - Part 5 : Anatomy of V2 Write API</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">31 Mar 2020</span>
     &raquo; <a href="/spark-3-introduction-part-3">Introduction to Spark 3.0 - Part 3 : Data Loading From Nested Folders</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">30 Mar 2020</span>
     &raquo; <a href="/spark-3-introduction-part-2">Introduction to Spark 3.0 - Part 2 : Multiple Column Feature Transformations in Spark ML</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">01 Apr 2020</span>
     &raquo; <a href="/spark-3-datasource-v2-part-5">Data Source V2 API in Spark 3.0 - Part 5 : Anatomy of V2 Write API</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">31 Mar 2020</span>
     &raquo; <a href="/spark-3-introduction-part-3">Introduction to Spark 3.0 - Part 3 : Data Loading From Nested Folders</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">30 Mar 2020</span>
     &raquo; <a href="/spark-3-introduction-part-2">Introduction to Spark 3.0 - Part 2 : Multiple Column Feature Transformations in Spark ML</a>    
   </li>           
         

   
   
 </ul>


 
<!--     
    <div id="disqus_thread" style="padding-top:4%;"></div>
     <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'personalblogmadhukar'; // required: replace example with your forum shortname
        var disqus_developer = 1;

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>