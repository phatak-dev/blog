<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Introduction to Spark 2.0 - Part 6 : Custom Optimizers in Spark SQL</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/introduction-to-spark-two-part-6">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Introduction to Spark 2.0 - Part 6 : Custom Optimizers in Spark SQL</h1>
  <p class="meta">May 20, 2016</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/spark-two"><span class="category">spark-two</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>Spark 2.0 is the next major release of Apache Spark. This release brings major changes to abstractions, API’s and libraries of the platform. This release sets the tone for next year’s direction of the framework. So understanding these few features is critical to understand for the ones who want to make use all the advances in this new release. So in this series of blog posts, I will be discussing about different improvements landing in Spark 2.0.</p>

<p>This is the sixth blog in series, where I will be discussing about adding custom optimizers to spark sql catalyst optimizer. You can access all the posts in the series <a href="/categories/spark-two/">here</a>.</p>

<p>TL;DR All code examples are available on <a href="https://github.com/phatak-dev/spark2.0-examples">github</a>.</p>

<h2 id="catalyst-optimizer">Catalyst optimizer</h2>

<p>Spark SQL uses an optimizer called catalyst to optimize all the queries written both in spark sql and dataframe dsl. This optimizer makes queries run much faster than their RDD counterparts. Spark keeps on improving this optimizer every version in order to improve performance without changing user code.</p>

<p>Catalyst is a modular library which is build as a rule based system. Each rule in the the framework focuses on the specific optimization. For example, rule like <em>ConstantFolding</em> focuses on removing constant expression from the query. For more information catalyst, you can refer to my earlier talk on <a href="/anatomy-of-spark-dataframe-api">anatomy of dataframe</a>.</p>

<p>In earlier versions of spark, if we wanted add our own optimizations, we need to change the source code of spark. This is not preferable in many cases where optimizations are only applicable to the domain or user specific problems. So developer community wanted to have a pluggable way to add their optimizations to the catalyst in runtime.</p>

<p>In Spark 2.0, we have an experimental API for adding user defined custom optimizations. In the rest of the blog I will be discussing about how to write an optimization rule and add it to catalyst.</p>

<h2 id="optimized-plan-for-a-dataframe">Optimized plan for a dataframe</h2>

<p>Before we write our optimization rule, let’s understand how to access the optimized plan in spark. The below code shows a simple example</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">sparkSession</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span><span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/main/resources/sales.csv"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">multipliedDF</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"amountPaid * 1"</span><span class="o">)</span>
<span class="nf">println</span><span class="o">(</span><span class="nv">multipliedDF</span><span class="o">.</span><span class="py">queryExecution</span><span class="o">.</span><span class="py">optimizedPlan</span><span class="o">.</span><span class="py">numberedTreeString</span><span class="o">)</span></code></pre></figure>

<p>In above code, we have loaded a csv file and multiplied one to one of the column. We can look at the optimized plan for that dataframe using <em>optimizedPlan</em> object on queryExecution. <em>queryExecution</em> allows us to access all the information related execution of the query. Optimized plan is one of them.</p>

<p>Every plan in spark is represented as a tree. So <em>numberedTreeString</em> method pretty prints the optimized plan. When we run this code we get below result.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>00 Project [(cast(amountPaid#3 as double) * 1.0) AS (amountPaid * 1)#5]
01 +- Relation[transactionId#0,customerId#1,itemId#2,amountPaid#3] csv
</code></pre></div></div>

<p>All plans are read bottom to top. The below are the two nodes of tree</p>

<ul>
  <li>
    <p>01 Relation - Signifies the dataframe we created from csv file</p>
  </li>
  <li>
    <p>00 Project - Signifies the projection</p>
  </li>
</ul>

<p>You can observe some of the casts added by the spark for correct results.</p>

<h2 id="writing-an-optimizer-rule">Writing an optimizer rule</h2>

<p>From the above plan, it’s clear that its going to multiply 1.0 to each of the value of column. But it’s not optimal plan. Whenever we see 1 in multiplication, we know it’s going to return exact same value. We can use this knowledge to write a rule and add smartness to the optimizer.</p>

<p>The following code show how to write such a rule.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">object</span> <span class="nc">MultiplyOptimizationRule</span> <span class="k">extends</span> <span class="nc">Rule</span><span class="o">[</span><span class="kt">LogicalPlan</span><span class="o">]</span> <span class="o">{</span>
    <span class="k">def</span> <span class="nf">apply</span><span class="o">(</span><span class="n">plan</span><span class="k">:</span> <span class="kt">LogicalPlan</span><span class="o">)</span><span class="k">:</span> <span class="kt">LogicalPlan</span> <span class="o">=</span> <span class="n">plan</span> <span class="n">transformAllExpressions</span> <span class="o">{</span>
      <span class="k">case</span> <span class="nc">Multiply</span><span class="o">(</span><span class="n">left</span><span class="o">,</span><span class="n">right</span><span class="o">)</span> <span class="k">if</span> <span class="nv">right</span><span class="o">.</span><span class="py">isInstanceOf</span><span class="o">[</span><span class="kt">Literal</span><span class="o">]</span> <span class="o">&amp;&amp;</span>
        <span class="nv">right</span><span class="o">.</span><span class="py">asInstanceOf</span><span class="o">[</span><span class="kt">Literal</span><span class="o">].</span><span class="py">value</span><span class="o">.</span><span class="py">asInstanceOf</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="o">==</span> <span class="mf">1.0</span> <span class="k">=&gt;</span>
        <span class="nf">println</span><span class="o">(</span><span class="s">"optimization of one applied"</span><span class="o">)</span>
        <span class="n">left</span>
    <span class="o">}</span>
  <span class="o">}</span></code></pre></figure>

<p>Here we are extending from Rule which operates on logical plan. Most of the rules are written as pattern matching in scala. In code, we are checking is the right operand is literal and it’s value is 1.0. Here we are very specific about where value 1 should appear. If it appears on the left it will not optimize. As it’s for example, for brevity I have not included checking for left also. But you can easily add.</p>

<p>So whenever we have right value as 1, we will skip the right expression altogether and return left.</p>

<h2 id="integrating-our-optimizer-rule">Integrating our optimizer rule</h2>

<p>Once we have our rule, next step is to add to the optimizer. The below code shows that.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">sparkSession</span><span class="o">.</span><span class="py">experimental</span><span class="o">.</span><span class="py">extraOptimizations</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">MultiplyOptimizationRule</span><span class="o">)</span></code></pre></figure>

<p>On spark session, we have an experimental object which exposes all the experimental API’s. Using this API, you can add list of custom rules to catalyst with <em>extraOptimizations</em>.</p>

<h2 id="using-the-custom-optimization">Using the custom optimization</h2>

<p>Once we have our rule added, we need to check it is applied or not. We will do same manipulation again as below code.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">multipliedDFWithOptimization</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"amountPaid * 1"</span><span class="o">)</span>
<span class="nf">println</span><span class="o">(</span><span class="s">"after optimization"</span><span class="o">)</span>
<span class="nf">println</span><span class="o">(</span><span class="nv">multipliedDFWithOptimization</span><span class="o">.</span><span class="py">queryExecution</span><span class="o">.</span>
<span class="nv">optimizedPlan</span><span class="o">.</span><span class="py">numberedTreeString</span><span class="o">)</span></code></pre></figure>

<p>If we observe the output now,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>00 Project [cast(amountPaid#3 as double) AS (amountPaid * 1)#7]
01 +- Relation[transactionId#0,customerId#1,itemId#2,amountPaid#3] csv
</code></pre></div></div>

<p>You can observe now that multiplication is gone. This denotes the our optimization is applied. You can access complete code <a href="https://github.com/phatak-dev/spark2.0-examples/blob/master/src/main/scala/com/madhukaraphatak/examples/sparktwo/CustomOptimizationExample.scala">here</a>.</p>

<p>In Spark 2.0 users can add their own custom rules to catalyst to optimize their code. This makes spark more developer friendly and powerful generic engine.</p>

<h2 id="references">References</h2>

<p>Catalyst: Allow adding custom optimizers - <a href="https://issues.apache.org/jira/browse/SPARK-9843">https://issues.apache.org/jira/browse/SPARK-9843</a></p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">18 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-5">Understanding Spark Connect API - Part 5: Dataframe Sharing Across Spark Sessions</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">16 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-4">Understanding Spark Connect API - Part 4: PySpark Example</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">30 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-3">Understanding Spark Connect API - Part 3: Scala API Example</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">18 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-5">Understanding Spark Connect API - Part 5: Dataframe Sharing Across Spark Sessions</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">16 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-4">Understanding Spark Connect API - Part 4: PySpark Example</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">30 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-3">Understanding Spark Connect API - Part 3: Scala API Example</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>