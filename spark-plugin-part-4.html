<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Spark Plugin Framework in 3.0 - Part 4 : Custom Metrics</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/spark-plugin-part-4">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Spark Plugin Framework in 3.0 - Part 4 : Custom Metrics</h1>
  <p class="meta">Apr 13, 2020</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/spark-three"><span class="category">spark-three</span></a>
    
    <a href="/categories/spark-plugin"><span class="category">spark-plugin</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>Spark 3.0 brings a new plugin framework to spark. This plugin framework allows users to plugin custom code at the driver and workers. This will allow for advanced monitoring and custom metrics tracking. This set of API’s are going to help tune spark better than before.</p>

<p>In this series of posts I will be discussing about the different aspects of plugin framework. This is the fourth post in the series, where we will discuss about how to implement the customer metrics. You can read all the posts in the series <a href="/categories/spark-plugin">here</a>.</p>

<h2 id="need-for-custom-metrics">Need For Custom Metrics</h2>

<p>Spark exposes wide variety of metrics for external consumption. These metrics include things like resource usage, scheduling delay, executor time etc. These metrics can be consumed using wide variety of sinks for further analysis. You can read about built-in metrics <a href="https://spark.apache.org/docs/latest/monitoring.html#executor-task-metrics">here</a>.</p>

<p>Even though these metrics are very useful, there are cases where you want to track your own metrics. These metrics may be amount of time a given condition is met or may be amount of data written to specific source. This kind of custom application specific metrics allow developers to optimise things specific to their applications.</p>

<p>Till spark 2.x, developers needed to build their own infrastructure to track these custom metrics. They were not able to reuse the spark metrics infrastructure for the custom metrics. But in 3.0 it’s going to change.</p>

<h2 id="custom-metrics-support-in-30">Custom Metrics Support in 3.0</h2>

<p>Spark added supported for tracking custom metrics using plugin framework from 3.0. Using custom plugin, we can track our own metrics and plug it into the spark metrics system.</p>

<p>The rest of post talks about how to define and consume custom metrics</p>

<h2 id="even-number-custom-metrics">Even Number Custom Metrics</h2>

<p>Let’s say we have a dataframe which contains number from 0 to 5000. We can create Dataframe as below.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"> <span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">sparkSession</span><span class="o">.</span><span class="py">range</span><span class="o">(</span><span class="mi">5000</span><span class="o">).</span><span class="py">repartition</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span></code></pre></figure>

<p>As operation we want to increment the each of the value by 1. In doing so, we also like to keep track how many even numbers are processed by the each executor. This tracking will be our custom metrics called <strong>even number metrics</strong>.</p>

<h2 id="custom-executor-plugin-for-custom-metrics">Custom Executor Plugin for Custom Metrics</h2>

<p>To track the above metrics, we need to run code in each executor spark spawns. Executor plugin will be helpful here.</p>

<p>The below are the steps for the same.</p>

<h3 id="defining-a-custom-spark-plugin">Defining a Custom Spark Plugin</h3>

<p>In below code we define the custom spark plugin.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">CustomMetricSparkPlugin</span> <span class="k">extends</span> <span class="nc">SparkPlugin</span></code></pre></figure>

<h3 id="return-empty-driver-plugin">Return Empty Driver Plugin</h3>

<p>For this use case, we don’t need a driver plugin so we return null for the same.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala">  <span class="k">override</span> <span class="k">def</span> <span class="nf">driverPlugin</span><span class="o">()</span><span class="k">:</span> <span class="kt">DriverPlugin</span> <span class="o">=</span> <span class="kc">null</span></code></pre></figure>

<h3 id="define-singleton-atomic-value-to-track-metric">Define Singleton Atomic Value to Track Metric</h3>

<p>We use a simple singleton in plugin code to track the latest value of the metric</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">object</span> <span class="nc">CustomMetricSparkPlugin</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">value</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Counter</span>
<span class="o">}</span></code></pre></figure>

<p>We define a counter which keeps our metric latest value. Counter is one of kind of metric type supported by spark. There are others also. You can read more about there <a href="https://metrics.dropwizard.io/3.1.0/getting-started/">here</a>.</p>

<p>There will one copy of this plugin for each executor spark runs.</p>

<h3 id="define-executor-plugin">Define Executor Plugin</h3>

<p>The below code defines a executor plugin and sets up custom metrics</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">override</span> <span class="k">def</span> <span class="nf">executorPlugin</span><span class="o">()</span><span class="k">:</span> <span class="kt">ExecutorPlugin</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ExecutorPlugin</span> <span class="o">{</span>
   <span class="k">override</span> <span class="k">def</span> <span class="nf">init</span><span class="o">(</span><span class="n">ctx</span><span class="k">:</span> <span class="kt">PluginContext</span><span class="o">,</span> <span class="n">extraConf</span><span class="k">:</span> <span class="kt">util.Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="k">val</span> <span class="nv">metricRegistry</span> <span class="k">=</span> <span class="nv">ctx</span><span class="o">.</span><span class="py">metricRegistry</span><span class="o">()</span>
      <span class="nv">metricRegistry</span><span class="o">.</span><span class="py">register</span><span class="o">(</span><span class="s">"evenMetrics"</span><span class="o">,</span><span class="nv">CustomMetricSparkPlugin</span><span class="o">.</span><span class="py">value</span><span class="o">)</span>
   <span class="o">}</span>
  <span class="o">}</span></code></pre></figure>

<p>In above code, we register a metrics using <strong>register</strong> method on MetricRegistery. We give a name called <strong>evenMetrics</strong>. The value of metric will take from the counter defined above. This counter will be polled for every 1s by default.</p>

<h2 id="using-custom-metrics-from-code">Using Custom Metrics From Code</h2>

<p>Once we setup the executor plugin and the metrics, we need to update the same from our code.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">incrementedDf</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">mapPartitions</span><span class="o">(</span><span class="n">iterator</span> <span class="k">=&gt;</span> <span class="o">{</span>
      <span class="k">var</span> <span class="n">evenCount</span> <span class="k">=</span> <span class="mi">0</span>
      <span class="k">val</span> <span class="nv">incrementedIterator</span> <span class="k">=</span> <span class="nv">iterator</span><span class="o">.</span><span class="py">toList</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">value</span> <span class="k">=&gt;</span> <span class="o">{</span>
        <span class="nf">if</span><span class="o">(</span><span class="n">value</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="n">evenCount</span> <span class="k">=</span> <span class="n">evenCount</span> <span class="o">+</span><span class="mi">1</span>
        <span class="n">value</span> <span class="o">+</span><span class="mi">1</span>
      <span class="o">}).</span><span class="py">toIterator</span>
      <span class="nv">CustomMetricSparkPlugin</span><span class="o">.</span><span class="py">value</span><span class="o">.</span><span class="py">inc</span><span class="o">(</span><span class="n">evenCount</span><span class="o">)</span>
      <span class="n">incrementedIterator</span>
    <span class="o">})</span></code></pre></figure>

<p>In above code, we are running our increment operation and also updating the metric value using <strong>inc</strong> operator. Also note that, we are going over data only once for both operation and metric calculation.</p>

<h2 id="setting-up-sink">Setting Up Sink</h2>

<p>To consume the metrics in spark, we need to specify it’s settings in <strong>metrics.properties</strong> file. The below code shows sample of the same.</p>

<figure class="highlight"><pre><code class="language-txt" data-lang="txt">*.sink.console.class=org.apache.spark.metrics.sink.ConsoleSink</code></pre></figure>

<p>In above line, we specify our sink as console which means we want to print the metrics to console.</p>

<h2 id="passing-metrics-file-in-spark-session">Passing Metrics File in Spark Session</h2>

<p>We need to specify the path of metrics files using <strong>spark.metrics.conf</strong> property. We can set the property as below</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"spark.metrics.conf"</span><span class="o">,</span><span class="s">"src/main/resources/metrics.properties"</span><span class="o">)</span></code></pre></figure>

<h2 id="code">Code</h2>

<p>You can access complete code on <a href="https://github.com/phatak-dev/spark-3.0-examples/tree/master/src/main/scala/com/madhukaraphatak/spark/core/plugins/custommetrics">github</a>.</p>

<h2 id="output">Output</h2>

<p>When you run the above example, you will observe the custom metrics with other spark metrics like as below</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">plugin.com.madhukaraphatak.spark.core.plugins.custommetrics
                       .CustomMetricSparkPlugin.evenMetrics
             count = 2500</code></pre></figure>

<p>As we are running on local, there is only one executor. That’s why all the even numbers are coming to single executor. But if you run the same code on cluster, you will see different numbers in different executors.</p>

<p>Now our custom metric is flowing as part of the spark metrics system.</p>

<h2 id="references">References</h2>

<p><a href="https://issues.apache.org/jira/browse/SPARK-24918">https://issues.apache.org/jira/browse/SPARK-24918</a></p>

<p><a href="https://github.com/cerndb/SparkPlugins">https://github.com/cerndb/SparkPlugins</a></p>

<h2 id="conclusion">Conclusion</h2>

<p>Spark plugin framework brings a powerful customization to spark ecosystem. In this post, we discussed how to use executor plugin to implement custom metrics for our programs.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">02 May 2025</span>
     &raquo; <a href="/rediscovering-implicits-scala-3-part-2">Rediscovering Implicits in Scala 3 - Part 2: Extension methods</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">17 Jan 2025</span>
     &raquo; <a href="/rediscovering-implicits-scala-3-part-1">Rediscovering Implicits in Scala 3 - Part 1: Implicit Parameters</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">18 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-5">Understanding Spark Connect API - Part 5: Dataframe Sharing Across Spark Sessions</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">18 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-5">Understanding Spark Connect API - Part 5: Dataframe Sharing Across Spark Sessions</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">16 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-4">Understanding Spark Connect API - Part 4: PySpark Example</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">30 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-3">Understanding Spark Connect API - Part 3: Scala API Example</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0ZF0EGSMTQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0ZF0EGSMTQ');
</script>


    </body>
</html>