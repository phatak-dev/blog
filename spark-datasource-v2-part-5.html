<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Exploring Spark DataSource V2 - Part 5  : Filter Push</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/spark-datasource-v2-part-5">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Exploring Spark DataSource V2 - Part 5  : Filter Push</h1>
  <p class="meta">May 25, 2018</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/datasource-v2-series"><span class="category">datasource-v2-series</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>In spark, data source is one of the foundational API for structured data analysis. Combined with dataframe and spark SQL abstractions, it makes spark one of the most complete structured data engine out there. You can read more about structured data analysis in spark <a href="/categories/datasource-series">here</a>.</p>

<p>Data source API was introduced in spark 1.3 along with dataframe abstraction. After that release, spark has undergone tremendous change. Spark has moved to custom memory management and with 2.0 we got Dataset , a better dataframe, abstraction. With these tremendous changes data source API needed to revisited.</p>

<p>So in 2.3 version, spark has released new version of data source API known as as data source V2. This API reflects all the learning spark developers learnt in last few releases. This API will be foundation for next few years of spark data source connectivity.</p>

<p>In this series of posts, I will be discussing about different parts of the API. We will be learning API by building data sources for different sources like flat file, relational databases etc.</p>

<p>This is fifth blog in the series where we discuss about implementing filter push. You can read all the posts in the series <a href="/categories/datasource-v2-series">here</a>.</p>

<h2 id="mysql-datasource">Mysql Datasource</h2>

<p>To understand how to implement filter push, we will be using a mysql datasource rather than in-memory datasource. A mysql datasource is similar to our earlier in-memory datasource, except it reads the data from mysql database rather than in-memory array. We will be using JDBC API to read from mysql. The below is the code in Reader interface to setup an iterator and read data.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"> <span class="k">def</span> <span class="nf">next</span> <span class="k">=</span>  <span class="o">{</span>
 <span class="nf">if</span><span class="o">(</span><span class="n">iterator</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="nv">url</span> <span class="k">=</span> <span class="s">"jdbc:mysql://localhost/mysql"</span>
    <span class="k">val</span> <span class="nv">user</span> <span class="k">=</span> <span class="s">"root"</span>
    <span class="k">val</span> <span class="nv">password</span> <span class="k">=</span> <span class="s">"abc123"</span>

    <span class="k">val</span> <span class="nv">properties</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">java</span><span class="o">.</span><span class="py">util</span><span class="o">.</span><span class="py">Properties</span><span class="o">()</span>
    <span class="nv">properties</span><span class="o">.</span><span class="py">setProperty</span><span class="o">(</span><span class="s">"user"</span><span class="o">,</span><span class="n">user</span><span class="o">)</span>
    <span class="nv">properties</span><span class="o">.</span><span class="py">setProperty</span><span class="o">(</span><span class="s">"password"</span><span class="o">,</span><span class="n">password</span><span class="o">)</span>


    <span class="k">val</span> <span class="nv">sparkSession</span> <span class="k">=</span> <span class="nv">SparkSession</span><span class="o">.</span><span class="py">builder</span><span class="o">.</span><span class="py">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">sparkSession</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">jdbc</span><span class="o">(</span><span class="n">url</span><span class="o">,</span><span class="n">getQuery</span><span class="o">,</span><span class="n">properties</span><span class="o">)</span>
    <span class="k">val</span> <span class="nv">rdd</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">rdd</span>
    <span class="k">val</span> <span class="nv">partition</span> <span class="k">=</span> <span class="nv">rdd</span><span class="o">.</span><span class="py">partitions</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="n">iterator</span> <span class="k">=</span> <span class="nv">rdd</span><span class="o">.</span><span class="py">iterator</span><span class="o">(</span><span class="n">partition</span><span class="o">,</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">TaskContext</span><span class="o">.</span><span class="py">get</span><span class="o">())</span>
   <span class="o">}</span>
   <span class="nv">iterator</span><span class="o">.</span><span class="py">hasNext</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="nf">get</span> <span class="k">=</span> <span class="o">{</span>
     <span class="nv">iterator</span><span class="o">.</span><span class="py">next</span><span class="o">()</span>
  <span class="o">}</span>
 </code></pre></figure>

<p>As you can see from above code, we are using jdbc and <em>sparkSession.read.jdbc</em> API’s to read the data. In our example, we are assuming all the data coming from single partition. We will fix this in upcoming examples.</p>

<p>Once we setup the iterator, get method is just calling next method on the iterators.</p>

<h2 id="filter-pushdown">Filter Pushdown</h2>

<p>In data sources, often we don’t want to read complete data from the source. In many cases, we will be analysing subset of data for our analysis. This is expressed as the filter in spark SQL code.</p>

<p>In normal sources, to implement filter, the complete data is brought to spark engine and then filtering is done. This is ok for sources such as file source or hdfs source. But for sources like relational databases this is very inefficient. These sources have an ability to filter data in source itself, rather than brining them to spark.</p>

<p>So in Datasource V2 there is new API to specify that source supports source level filtering. This helps us to reduce the amount of data transfer between the source and spark.</p>

<h2 id="filter-push-in-mysql-source">Filter Push in Mysql Source</h2>

<p>The below are the steps to add filter push support for the mysql data source.</p>

<h3 id="1-implement-supportspushdownfilter-interface">1. Implement SupportsPushDownFilter Interface</h3>

<p>We need to implement <em>SupportsPushDownFilter</em> interface to indicate to the spark engine that source supports filter pushdown. This needs to be implemented by Datasource Reader.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">SimpleMysqlDataSourceReader</span><span class="o">()</span> <span class="k">extends</span> <span class="nc">DataSourceReader</span> <span class="k">with</span> <span class="nc">SupportsPushDownFilters</span> <span class="o">{</span>
  <span class="k">var</span> <span class="n">pushedFilters</span><span class="k">:</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Filter</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Filter</span><span class="o">]()</span>

  <span class="k">def</span> <span class="nf">pushFilters</span><span class="o">(</span><span class="n">filters</span><span class="k">:</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Filter</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
     <span class="nf">println</span><span class="o">(</span><span class="nv">filters</span><span class="o">.</span><span class="py">toList</span><span class="o">)</span>
     <span class="n">pushedFilters</span> <span class="k">=</span> <span class="n">filters</span>
     <span class="n">pushedFilters</span>
  <span class="o">}</span></code></pre></figure>

<p>In above code, we have implemented the interface. Then we have overridden the <em>pushedFilters</em> method to capture the filters. In this code, we just remember the filters in a variable.</p>

<h3 id="2-implement-filter-pushdown-in-mysql-query">2. Implement Filter Pushdown in Mysql Query</h3>

<p>Once we have captured the filters, we need to use them to create jdbc queries to push them to the source. This is implemented in <em>DataReader</em>.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">SimpleMysqlDataReader</span><span class="o">(</span><span class="n">pushedFilters</span><span class="k">:</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Filter</span><span class="o">])</span> <span class="k">extends</span> <span class="nc">DataReader</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">val</span> <span class="nv">getQuery</span><span class="k">:</span><span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
   <span class="nf">if</span><span class="o">(</span><span class="n">pushedFilters</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="nv">pushedFilters</span><span class="o">.</span><span class="py">isEmpty</span><span class="o">)</span>
     <span class="s">"(select user from user)a"</span>
   <span class="k">else</span> <span class="o">{</span>
    <span class="nf">pushedFilters</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="n">filter</span> <span class="k">:</span> <span class="kt">EqualTo</span> <span class="o">=&gt;</span>
    <span class="k">val</span> <span class="nv">condition</span> <span class="k">=</span> <span class="n">s</span><span class="s">"${filter.attribute} = '${filter.value}'"</span>
    <span class="n">s</span><span class="s">"(select user from user where $condition)a"</span>
    <span class="k">case</span> <span class="k">_</span> <span class="o">=&gt;</span><span class="s">"(select user from user)a"</span>
    <span class="o">}</span>
   <span class="o">}</span>
  <span class="o">}</span></code></pre></figure>

<p>In above code, the pushed filters are taken an class parameters. Once we have filters available to us, we write a method which generates the queries depending upon the filters.In the query column name and table name is hard coded. This is done to simplify over all code. In real world scenario these will be passed as options.</p>

<p>In the code, if there is no filter we just read all the data. But if there is a filter, we generate the table query which will have a where condition. In our example, we only support <em>equal to</em> . But you can support other ones also.</p>

<p>Also in code, we are looking at second filter ( 1 index in pushed filters ). There is  a reason for that. We will understand more when we see in a example.</p>

<p>You can access complete code on <a href="https://github.com/phatak-dev/spark2.0-examples/blob/master/src/main/scala/com/madhukaraphatak/examples/sparktwo/datasourcev2/SimpleMysqlDataSource.scala">github</a>.</p>

<p>##Using Mysql Datasource with Filter Push</p>

<p>Once we have implemented filter push, we can test it from an example.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">simpleMysqlDf</span> <span class="k">=</span> <span class="nv">sparkSession</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">format</span><span class="o">(</span>
<span class="s">"com.madhukaraphatak.examples.sparktwo.
         datasourcev2.simplemysql"</span><span class="o">)</span>
         <span class="o">.</span><span class="py">load</span><span class="o">()</span>
<span class="nv">simpleMysqlDf</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="s">"user=\"root\""</span><span class="o">).</span><span class="py">show</span><span class="o">()</span></code></pre></figure>

<p>In above code, we read from our source and add a filter for user.</p>

<p>The above code prints below result</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">List(IsNotNull(user), EqualTo(user,root))

+----+
|user|
+----+
|root|
|root|
|root|
|root|
+----+</code></pre></figure>

<p>The first line of result signifies the filters pushed for the source. As you can see here, even though we have specified only one filter in our spark sql code, spark has pushed two of them. The reason is , spark always checks for the rows where there are no nulls. This simplifies upstream code to do the aggregations etc. The second filter is the one which we are interested.</p>

<p>Once filter is done, we see all the rows where filter matches. You can verify the is filter is pushed or not from mysql logs. The mysql log should show a query like below. You may need to enable logging in mysql.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">119 Query     SELECT `user` FROM (select user from user where user = 'root')a</code></pre></figure>

<p>Above line makes sures that actual source is getting query with filter.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we have discussed how to implement filter push down in datasource V2 API. Implementing filter pushdown, greatly reduces the data transfer between source and spark engine, which intern makes the overall data source more performant.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">19 May 2025</span>
     &raquo; <a href="/rediscovering-implicits-scala-3-part-3">Rediscovering Implicits in Scala 3 - Part 3: Summoning Implicits</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">02 May 2025</span>
     &raquo; <a href="/rediscovering-implicits-scala-3-part-2">Rediscovering Implicits in Scala 3 - Part 2: Extension methods</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">17 Jan 2025</span>
     &raquo; <a href="/rediscovering-implicits-scala-3-part-1">Rediscovering Implicits in Scala 3 - Part 1: Implicit Parameters</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">18 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-5">Understanding Spark Connect API - Part 5: Dataframe Sharing Across Spark Sessions</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">16 Aug 2023</span>
     &raquo; <a href="/understanding-spark-connect-4">Understanding Spark Connect API - Part 4: PySpark Example</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">30 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-3">Understanding Spark Connect API - Part 3: Scala API Example</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0ZF0EGSMTQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0ZF0EGSMTQ');
</script>


    </body>
</html>