<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Auto Scaling Spark in Kubernetes - Part 2 : Spark Cluster Setup</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/horizontal-scaling-k8s-part-2">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Auto Scaling Spark in Kubernetes - Part 2 : Spark Cluster Setup</h1>
  <p class="meta">Oct 30, 2019</p>
  <div class="catagories">
    
    <a href="/categories/kubernetes"><span class="category">kubernetes</span></a>
    
    <a href="/categories/k8s-horizontal-scaling"><span class="category">k8s-horizontal-scaling</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>Kubernetes makes it easy to run services on scale. With kubernetes abstractions, it’s easy to setup a cluster of spark, hadoop or database on large number of nodes. Kubernetes takes care of handling tricky pieces like node assignment,service discovery, resource management of a distributed system. We have discussed how it can be used for spark clustering in our earlier <a href="/categories/kubernetes-series">series</a>.</p>

<p>As the services are becoming more and more dynamic, handling resource needs statically is becoming challenge. With cloud being prevalent, users expect their infrastructure to scale with usage. For example, spark cluster on kubernetes should be able to scale up or down depending upon the load.</p>

<p>Kubernetes system can scaled manually by increasing or decreasing the number of replicas. You can refer to <a href="/scaling-spark-with-kubernetes-part-7">this</a> post for more information. But doing this manually means lot of work. Isn’t it better if kubernetes can auto manage the same?</p>

<p>Kubernetes Horizontal Pod AutoScaler(HPA) is one of the controller in the kubernetes which is built to the auto management of scaling. It’s very powerful tool which allows user to utilize resources of the cluster effectively.</p>

<p>In this series of post, I will be discussing about HPA with respect to auto scaling spark. This is the second post in the series which talks about how to setup spark cluster to use the auto scaling. You can find all the posts in the series <a href="/categories/k8s-horizontal-scaling">here</a>.</p>

<h2 id="spark-cluster-setup-on-kubernetes">Spark Cluster Setup on Kubernetes</h2>

<p>In earlier series of posts we have discussed how to setup the spark cluster on kubernetes. If you have not read it, read it in below link before continuing.</p>

<p><a href="/categories/kubernetes-series/">Spark Cluster Setup on Kubernetes</a>.</p>

<h2 id="enabling-metrics-server-in-minikube">Enabling Metrics Server in Minikube</h2>

<p>As we discussed in earlier post, metrics server is an important part of the auto scaling. In normal kubernetes clusters, it’s enabled by default. But if you are using minikube to test the HPA you need to enabled it explicitly.</p>

<p>The below is the command to enable. This needs minikube restart.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">minikube addons <span class="nb">enable </span>metrics-server</code></pre></figure>

<p>Once it’s enabled, you should be able to see it in the list of addons.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">minikube addons list</code></pre></figure>

<figure class="highlight"><pre><code class="language-text" data-lang="text">- addon-manager: enabled
- dashboard: enabled
- default-storageclass: enabled
- efk: disabled
- freshpod: disabled
- gvisor: disabled
- heapster: disabled
- helm-tiller: disabled
- ingress: disabled
- ingress-dns: disabled
- logviewer: disabled
- metrics-server: enabled
- nvidia-driver-installer: disabled
- nvidia-gpu-device-plugin: disabled
- registry: disabled
- registry-creds: disabled
- storage-provisioner: enabled
- storage-provisioner-gluster: disabled</code></pre></figure>

<h2 id="defining-the-resource-usage-for-spark-worker">Defining the Resource Usage For Spark Worker</h2>

<p>In our spark setup, we need to auto scale spark worker. To auto scale the same, we need to define the it’s resource needs as below.</p>

<h3 id="restricting-at-pod-level">Restricting at Pod Level</h3>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
       <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">spark-2.1.0-bin-hadoop2.6</span>
        <span class="na">imagePullPolicy </span><span class="pi">:</span> <span class="s2">"</span><span class="s">IfNotPresent"</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">7078</span>
          <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">limits</span><span class="pi">:</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1"</span>
          <span class="na">requests</span><span class="pi">:</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1"</span>
        <span class="na">command</span><span class="pi">:</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">/bin/bash"</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">-c"</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">--"</span>
        <span class="na">args </span><span class="pi">:</span>
                <span class="pi">-</span> <span class="s1">'</span><span class="s">./start-worker.sh;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">infinity'</span></code></pre></figure>

<p>In above YAML, we have request for the single cpu for every worker in our cluster.</p>

<h3 id="restricting-at-spark-level">Restricting at Spark Level</h3>

<p>By default spark doesn’t respect the resource restriction set by kubernetes. So we need to pass this information when we start the slave. So the below changes are done to our <strong>start-worker.sh</strong>.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c">#!/bin/sh</span>

<span class="nb">.</span> /start-common.sh

/opt/spark/sbin/start-slave.sh <span class="nt">--cores</span> 1 spark://spark-master:7077</code></pre></figure>

<p>In above code, <em>–cores 1</em> will tell to the spark that this slave should use only one core.</p>

<h2 id="enabling-external-shuffle-service">Enabling External Shuffle Service</h2>

<p>To use the automatically scaled pods, we need to run the spark in dynamic allocation mode. We will talk more about this mode in next post. One of the pre requisite for the dynamic allocation is external shuffle service. This is enabled in each worker node using below configuration in <strong>spark-default.conf</strong>.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">spark.shuffle.service.enabled   true</code></pre></figure>

<h2 id="rebuilding-the-docker-image">Rebuilding the Docker Image</h2>

<p>As we done number of changes to the our setup, we need to rebuild the docker image. You can read about building the image <a href="/scaling-spark-with-kubernetes-part-5/">here</a>.</p>

<h2 id="starting-the-cluster">Starting the Cluster</h2>

<p>Now we have done all the necessary changes. We can start the cluster. You can follow steps laid out <a href="/scaling-spark-with-kubernetes-part-6">here</a> for the same.</p>

<h2 id="the-state-of-the-cluster">The State of the Cluster</h2>

<p>Once the cluster is successfully started, you should be able to see one worker in spark master as shown below image.</p>

<p><img src="/images/hpa/spark-master-single-slave.png" alt="Spark Master with Single Slave" />.</p>

<h2 id="code">Code</h2>

<p>You can access all the configuration and scripts on <a href="https://github.com/phatak-dev/kubernetes-spark/tree/autoscaling">github</a>.</p>

<h2 id="conclusion">Conclusion</h2>
<p>In this post we discussed how to prepare spark cluster on kubernetes to be ready to make use of the auto scaling.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">30 Oct 2019</span>
     &raquo; <a href="/horizontal-scaling-k8s-part-3">Auto Scaling Spark in Kubernetes - Part 3 : Scaling Spark Workers</a>    
   </li>           
         

            
          

            
    
    <li>    
     <span class="post-date">30 Oct 2019</span>
     &raquo; <a href="/horizontal-scaling-k8s-part-1">Auto Scaling Spark in Kubernetes - Part 1 : Introduction</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">30 Oct 2019</span>
     &raquo; <a href="/horizontal-scaling-k8s-part-3">Auto Scaling Spark in Kubernetes - Part 3 : Scaling Spark Workers</a>    
   </li>           
         

            
          

            
    
    <li>    
     <span class="post-date">30 Oct 2019</span>
     &raquo; <a href="/horizontal-scaling-k8s-part-1">Auto Scaling Spark in Kubernetes - Part 1 : Introduction</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0ZF0EGSMTQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0ZF0EGSMTQ');
</script>


    </body>
</html>