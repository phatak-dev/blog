<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Exploring Spark DataSource V2 - Part 4  : In-Memory DataSource with Partitioning</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="http://blog.madhukaraphatak.com/spark-datasource-v2-part-4">
     <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Exploring Spark DataSource V2 - Part 4  : In-Memory DataSource with Partitioning</h1>
  <p class="meta">Apr 24, 2018</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/datasource-v2-series"><span class="category">datasource-v2-series</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>In spark, data source is one of the foundational API for structured data analysis. Combined with dataframe and spark SQL abstractions, it makes spark one of the most complete structured data engine out there. You can read more about structured data analysis in spark <a href="/categories/datasource-series">here</a>.</p>

<p>Data source API was introduced in spark 1.3 along with dataframe abstraction. After that release, spark has undergone tremendous change. Spark has moved to custom memory management and with 2.0 we got Dataset , a better dataframe, abstraction. With these tremendous changes data source API needed to revisited.</p>

<p>So in 2.3 version, spark has released new version of data source API known as as data source V2. This API reflects all the learning spark developers learnt in last few releases. This API will be foundation for next few years of spark data source connectivity.</p>

<p>In this series of posts, I will be discussing about different parts of the API. We will be learning API by building data sources for different sources like flat file, relational databases etc.</p>

<p>This is fourth blog in the series where we discuss about adding partition support for in-memory data source we built in last post. You can read all the posts in the series <a href="/categories/datasource-v2-series">here</a>.</p>

<h2 id="partitions">Partitions</h2>
<p>In spark, number of partitions for a given Dataframe is decided at the driver. As most of the partition logic is driven based on size of data, it’s a metadata operation.</p>

<p>The in-memory data source which we built in last post had only one partition. In this post, we will see how to add multiple partitions and how to read them.</p>

<h2 id="adding-multiple-partitions">Adding Multiple Partitions</h2>

<p>As we discussed in last blog, number of partitions for a given dataframe is decided by number of data factory objects we create. That’s why it was an array. As these factory objects are created at driver, they should not be using actual data itself.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">SimpleDataSourceReader</span> <span class="k">extends</span> <span class="nc">DataSourceReader</span> <span class="o">{</span>

<span class="k">def</span> <span class="n">readSchema</span><span class="o">()</span> <span class="k">=</span> <span class="nc">StructType</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="nc">StructField</span><span class="o">(</span><span class="s">"value"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">)))</span>

<span class="k">def</span> <span class="n">createDataReaderFactories</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">factoryList</span> <span class="k">=</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="nc">ArrayList</span><span class="o">[</span><span class="kt">DataReaderFactory</span><span class="o">[</span><span class="kt">Row</span><span class="o">]]</span>
    <span class="n">factoryList</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">SimpleDataSourceReaderFactory</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">4</span><span class="o">))</span>
    <span class="n">factoryList</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">SimpleDataSourceReaderFactory</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">9</span><span class="o">))</span>                                                               <span class="n">factoryList</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>In above code, we have created two factories. Each one of them takes the index in the array which they need to read. This indexes make sure that we are reading distinct data in each partition.</p>

<p>As we created two factories, we will have two partitions in resulting dataframe.</p>

<h2 id="reading-from-partitions">Reading From Partitions</h2>

<p>Once we define the partitions, we need to update our <em>DatasourceReader</em> to read from specific partitions. The below is the code for the same</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">SimpleDataSourceReaderFactory</span><span class="o">(</span><span class="k">var</span> <span class="n">start</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="k">var</span> <span class="n">end</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> 
         <span class="k">extends</span> <span class="nc">DataReaderFactory</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">with</span> <span class="nc">DataReader</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">createDataReader</span> <span class="k">=</span> <span class="k">new</span> 
      <span class="nc">SimpleDataSourceReaderFactory</span><span class="o">(</span><span class="n">start</span><span class="o">,</span> <span class="n">end</span><span class="o">)</span>
                                                                                                                             <span class="k">val</span> <span class="n">values</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"1"</span><span class="o">,</span> <span class="s">"2"</span><span class="o">,</span> <span class="s">"3"</span><span class="o">,</span> <span class="s">"4"</span><span class="o">,</span> 
                <span class="s">"5"</span><span class="o">,</span> <span class="s">"6"</span><span class="o">,</span> <span class="s">"7"</span><span class="o">,</span> <span class="s">"8"</span><span class="o">,</span> <span class="s">"9"</span><span class="o">,</span> <span class="s">"10"</span><span class="o">)</span>
  <span class="k">var</span> <span class="n">index</span> <span class="k">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="n">next</span> <span class="k">=</span> <span class="n">start</span> <span class="o">&lt;=</span> <span class="n">end</span>

  <span class="k">def</span> <span class="n">get</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">row</span> <span class="k">=</span> <span class="nc">Row</span><span class="o">(</span><span class="n">values</span><span class="o">(</span><span class="n">start</span><span class="o">))</span>
    <span class="n">start</span> <span class="k">=</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">row</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">close</span><span class="o">()</span> <span class="k">=</span> <span class="nc">Unit</span>
<span class="o">}</span></code></pre></div>

<p>In the above code, we get start and end from the factory objects. These will be start and end indexes. Using these two we will know which are the indexes to read.</p>

<p>Now each of these readers will read distinct parts of the array thus giving partition level parallelism.</p>

<p>You can access complete code of the connector on <a href="https://github.com/phatak-dev/spark2.0-examples/blob/master/src/main/scala/com/madhukaraphatak/examples/sparktwo/datasourcev2/SimpleMultiDataSource.scala">github</a>.</p>

<h2 id="printing-number-of-partitions">Printing Number of Partitions</h2>

<p>The below is the code to read the data using above connector and checking the number of partitions. When you run the code it should print 2.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">simpleMultiDf</span> <span class="k">=</span> <span class="n">sparkSession</span><span class="o">.</span><span class="n">read</span><span class="o">.</span>
    <span class="n">format</span><span class="o">(</span><span class="s">"com.madhukaraphatak.examples.sparktwo.datasourcev2.simplemulti"</span><span class="o">)</span>
    <span class="o">.</span><span class="n">load</span><span class="o">()</span>            
<span class="n">simpleMultiDf</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
<span class="n">println</span><span class="o">(</span><span class="s">"number of partitions in simple 
       multi source is "</span><span class="o">+</span><span class="n">simpleMultiDf</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">getNumPartitions</span><span class="o">)</span></code></pre></div>

<h2 id="conclusion">Conclusion</h2>
<p>In this post, we discussed about how to add partitioning support for our in memory connector. The factory API of the datasource v2 allows us to separate partitioning concerns between driver and executor.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">02 Nov 2020</span>
     &raquo; <a href="/spark-3-introduction-part-10">Introduction to Spark 3.0 - Part 10 : Ignoring Data Locality in Spark</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">22 Apr 2020</span>
     &raquo; <a href="/spark-3-datasource-v2-part-6">Data Source V2 API in Spark 3.0 - Part 6 : MySQL Source</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">21 Apr 2020</span>
     &raquo; <a href="/spark-3-introduction-part-9">Introduction to Spark 3.0 - Part 9 : Join Hints in Spark SQL</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-2">Pandas API on Apache Spark - Part 2: Hello World</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-1">Pandas API on Apache Spark - Part 1: Introduction</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">11 Nov 2020</span>
     &raquo; <a href="/barrier-execution-mode-part-2">Barrier Execution Mode in Spark 3.0 - Part 2 : Barrier RDD</a>    
   </li>           
         

   
   
 </ul>


 
<!--     
    <div id="disqus_thread" style="padding-top:4%;"></div>
     <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'personalblogmadhukar'; // required: replace example with your forum shortname
        var disqus_developer = 1;

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>