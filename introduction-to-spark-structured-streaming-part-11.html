<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Introduction to Spark Structured Streaming - Part 11 : Event Time</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/introduction-to-spark-structured-streaming-part-11">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Introduction to Spark Structured Streaming - Part 11 : Event Time</h1>
  <p class="meta">Sep 12, 2017</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/introduction-structured-streaming"><span class="category">introduction-structured-streaming</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>Structured Streaming is a new streaming API, introduced in spark 2.0, rethinks stream processing in spark land. It models stream
as an infinite table, rather than discrete collection of data. It’s a radical departure from models of other stream processing frameworks like
storm, beam, flink etc. Structured Streaming is the first API to build stream processing on top of SQL engine.</p>

<p>Structured Streaming was in alpha in 2.0 and 2.1. But with release 2.2 it has hit stable status. In next few releases,
it’s going to be de facto way of doing stream processing in spark. So it will be right time to make ourselves familiarise
with this new API.</p>

<p>In this series of posts, I will be discussing about the different aspects of the structured streaming API. I will be discussing about
new API’s, patterns and abstractions to solve common stream processing tasks.</p>

<p>This is the eleventh post in the series. In this post, we discuss about event time abstraction. You 
can read all the posts in the series <a href="/categories/introduction-structured-streaming">here</a>.</p>

<p>TL;DR You can access code on <a href="https://github.com/phatak-dev/spark2.0-examples/tree/master/src/main/scala/com/madhukaraphatak/examples/sparktwo/streaming">github</a>.</p>

<h2 id="event-time-abstraction">Event Time Abstraction</h2>

<p>In last <a href="/introduction-to-spark-structured-streaming-part-10/">post</a> we discussed about the ingestion time abstraction. In this post, we will discuss about event time abstraction.</p>

<p>Event time, as name suggests, is the time when event is generated. Normally the data which we collect from sources like sensors, logs have a time embedded in them. This time signifies when a given event is generated at the source. Structured streaming allows us to work with this time, with event time support in the framework level.</p>

<p>Whenever we talk about time, normally we need to address two different components of it. They are</p>

<ul>
  <li>
    <p>When a given event is generated?</p>
  </li>
  <li>
    <p>How long ago a given event is generated?</p>
  </li>
</ul>

<p>The first question is about where a given event fits in event time line. The second question deals about tracking  of passing of time. Answering these two questions helps us to define how event time works in structured streaming.</p>

<h2 id="analysing-stock-data-using-event-time">Analysing Stock Data using Event Time</h2>

<p>In this example, we analyse the stock data using event time abstraction. As each stock event comes with a timestamp, we can use that time to define aggregations. We will be using socket stream as our source.</p>

<h3 id="reading-data-from-socket">Reading Data From Socket</h3>

<p>The below code is to read the data from socket.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">socketStreamDs</span> <span class="k">=</span> <span class="nv">sparkSession</span><span class="o">.</span><span class="py">readStream</span>
  <span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"socket"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"host"</span><span class="o">,</span> <span class="s">"localhost"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"port"</span><span class="o">,</span> <span class="mi">50050</span><span class="o">)</span>
  <span class="o">.</span><span class="py">load</span><span class="o">()</span>
  <span class="o">.</span><span class="py">as</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span></code></pre></figure>

<h3 id="extracting-time-from-stream">Extracting Time from Stream</h3>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">Stock</span><span class="o">(</span><span class="n">time</span><span class="k">:</span><span class="kt">Long</span><span class="o">,</span> <span class="n">symbol</span><span class="k">:</span><span class="kt">String</span><span class="o">,</span><span class="n">value</span><span class="k">:</span><span class="kt">Double</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stockDs</span> <span class="k">=</span> <span class="nv">socketStreamDs</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">value</span> <span class="k">=&gt;</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">columns</span> <span class="k">=</span> <span class="nv">value</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">","</span><span class="o">)</span>
  <span class="nc">Stock</span><span class="o">(</span><span class="k">new</span> <span class="nc">Timestamp</span><span class="o">(</span><span class="nf">columns</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">toLong</span><span class="o">),</span> <span class="nf">columns</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span> <span class="nf">columns</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="py">toDouble</span><span class="o">)</span>
<span class="o">})</span></code></pre></figure>

<p>In above code, we declared a model which tracks stock price in a given point of time. The first field is timestamp of stock, then second is the symbol and third one is the value of the stock at that point of given time. Normally stock price analysis depends on event time rather than processing time as they want to correlate the change in stock prices when they happened in the market rather than they ended up in our processing engine.</p>

<p>So once we define the model, we convert of string network stream into model which we want to use. So the time in the model, signifies when this stock reading is done.</p>

<h3 id="defining-window-on-event-time">Defining Window on Event Time</h3>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala">    <span class="k">val</span> <span class="nv">windowedCount</span> <span class="k">=</span> <span class="n">stockDs</span>
      <span class="o">.</span><span class="py">groupBy</span><span class="o">(</span>
        <span class="nf">window</span><span class="o">(</span><span class="n">$</span><span class="s">"time"</span><span class="o">,</span> <span class="s">"10 seconds"</span><span class="o">)</span>
      <span class="o">)</span>
      <span class="o">.</span><span class="py">sum</span><span class="o">(</span><span class="s">"value"</span><span class="o">)</span></code></pre></figure>

<p>The above code defines the window which aggregates the stock value for last 10 seconds.</p>

<p>You can access complete code on <a href="https://github.com/phatak-dev/spark2.0-examples/blob/master/src/main/scala/com/madhukaraphatak/examples/sparktwo/streaming/EventTimeExample.scala">github</a>.</p>

<h2 id="passing-of-time">Passing of time</h2>

<p>Whenever we say, we want to calculate max of a stock in last 10 seconds, how spark knows all the records for that 10 seconds are reached? It’s the way of saying how spark knows the passage of time in the source? We cannot use system clocks because there will be delay between these two systems.</p>

<p>As we discussed in previous post, watermarks are the solution to this problem. Watermark signify the passage of time in source which will help to spark to understand flow in time.</p>

<p>By default spark uses the window time column to track the passing of time with option of infinite delay. So in this model all windows are remembered as state,so that even if the event delays long time, spark will calculate the right value.But this creates an issue.As time goes number of windows increases and they use more and more resources. We can limit the state, number of windows to be remembered, using custom watermarks. We will discuss more about it in next post.</p>

<h2 id="running-the-example">Running the Example</h2>

<p>Enter the below records in socket console. These are records for AAPL with time stamps.</p>

<h3 id="first-event">First Event</h3>

<p>The first records is for time Wed, 27 Apr 2016 11:34:22 GMT.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">1461756862000,"aapl",500.0</code></pre></figure>

<p>Spark outputs below results which indicates start of window</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">-------------------------------------------
Batch: 0
-------------------------------------------
+---------------------------------------------+----------+
|window                                       |sum(value)|
+---------------------------------------------+----------+
|[2016-04-27 17:04:20.0,2016-04-27 17:04:30.0]|500.0     |
+---------------------------------------------+----------+</code></pre></figure>

<h3 id="event-after-5-seconds">Event after 5 seconds</h3>

<p>Now we send the next record, which is after 5 seconds. This signifies to spark that, 5 seconds have passed in source. So spark will be updating the same window. This event is for time Wed, 27 Apr 2016 11:34:27 GMT</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">1461756867001,"aapl",600.0</code></pre></figure>

<p>The output of the spark will be as below. You can observe from output, spark is updating same window.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">-------------------------------------------
Batch: 1
-------------------------------------------
+---------------------------------------------+----------+
|window                                       |sum(value)|
+---------------------------------------------+----------+
|[2016-04-27 17:04:20.0,2016-04-27 17:04:30.0]|1100.0    |
+---------------------------------------------+----------+</code></pre></figure>

<h3 id="event-after-11-seconds">Event after 11 seconds</h3>

<p>Now we send another event, which is after 6 seconds from this time. Now spark understands 11 seconds have been passed. This event is for Wed, 27 Apr 2016 11:34:32 GMT</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">1461756872000,"aapl",400.0</code></pre></figure>

<p>Now spark completes the first window and add the above event to next window.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">-------------------------------------------
Batch: 2
-------------------------------------------
+---------------------------------------------+----------+
|window                                       |sum(value)|
+---------------------------------------------+----------+
|[2016-04-27 17:04:20.0,2016-04-27 17:04:30.0]|1100.0    |
|[2016-04-27 17:04:30.0,2016-04-27 17:04:40.0]|400.0     |
+---------------------------------------------+----------+</code></pre></figure>

<h3 id="late-event">Late Event</h3>

<p>Let’s say we get an event which got delayed. It’s an event is for Wed, 27 Apr 2016 11:34:27 which is 5 seconds before the last event.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">1461756867001,"aapl",200.0</code></pre></figure>

<p>If you observe the spark result now, you can observe that it’s added it to right window.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">-------------------------------------------
Batch: 3
-------------------------------------------
+---------------------------------------------+----------+
|window                                       |sum(value)|
+---------------------------------------------+----------+
|[2016-04-27 17:04:20.0,2016-04-27 17:04:30.0]|1300.0    |
|[2016-04-27 17:04:30.0,2016-04-27 17:04:40.0]|400.0     |
+---------------------------------------------+----------+</code></pre></figure>

<h2 id="conclusion">Conclusion</h2>

<p>In this post we understood how to use event time abstraction in structured streaming.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">17 Oct 2022</span>
     &raquo; <a href="/latest-java-4">Latest Java Features from a Scala Dev Perspective - Part 4: Higher Order Functions</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">10 Oct 2022</span>
     &raquo; <a href="/latest-java-3">Latest Java Features from a Scala Dev Perspective - Part 3: Functional Interfaces</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">14 Sep 2022</span>
     &raquo; <a href="/latest-java-2">Latest Java Features from a Scala Dev Perspective - Part 2: Lambda Expressions</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-2">Pandas API on Apache Spark - Part 2: Hello World</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-1">Pandas API on Apache Spark - Part 1: Introduction</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">11 Nov 2020</span>
     &raquo; <a href="/barrier-execution-mode-part-2">Barrier Execution Mode in Spark 3.0 - Part 2 : Barrier RDD</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>