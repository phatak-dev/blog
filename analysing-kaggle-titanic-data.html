<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Analysing Kaggle Titanic Survival Data using Spark ML</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/analysing-kaggle-titanic-data">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Analysing Kaggle Titanic Survival Data using Spark ML</h1>
  <p class="meta">Dec 7, 2017</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/datascience"><span class="category">datascience</span></a>
    
    <a href="/categories/kaggle"><span class="category">kaggle</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>Kaggle is one of the biggest data and code repository for data science. Recently I have started learning various python data science tools like scikit-learn,tensorflow, etc. As to practice these tools, I have started exploring the kaggle datasets. In kaggle, you will find many notebooks(kernels) which explore the data in various ways. Most of them are written in python and R.</p>

<p>Kaggle has a introductory dataset called titanic survivor dataset for learning basics of machine learning process. In this post, I have taken some of the ideas to analyse this dataset from kaggle kernels and implemented using spark ml. So as part of the analysis, I will be discussing about preprocessing the data, handling null values and running cross validation to get optimal performance.</p>

<h2 id="titanic-survivor-dataset">Titanic Survivor Dataset</h2>

<p>Titanic survivor dataset captures the various details of people who survived or not survived in the shipwreck. Using this data, you need to build a model which predicts probability of someone’s survival based on attributes like sex, cabin etc. It’s a classification problem.</p>

<p>You can learn more about the dataset at <a href="https://www.kaggle.com/c/titanic">kaggle</a>.</p>

<p>The rest of the post will discuss various steps to build the model.</p>

<p>TL;DR You can access all the code on <a href="https://github.com/phatak-dev/spark-ml-kaggle">github</a>.</p>

<h2 id="1-preprocessing">1. Preprocessing</h2>

<p>First part of data analysis to load data and pre-process to fit to machine learning.</p>

<h3 id="11-loading-csv-data">1.1 Loading CSV data</h3>

<p>First we load the data using spark data source API.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">sparkSession</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">option</span><span class="o">(</span><span class="s">"inferSchema"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/main/resources/titanic/train.csv"</span><span class="o">)</span> 
<span class="nv">df</span><span class="o">.</span><span class="py">printSchema</span><span class="o">()</span></code></pre></figure>

<p>The below is the schema of data</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">root
 |-- PassengerId: integer (nullable = true)
 |-- Survived: integer (nullable = true)
 |-- Pclass: integer (nullable = true)
 |-- Name: string (nullable = true)
 |-- Sex: string (nullable = true)
 |-- Age: double (nullable = true)
 |-- SibSp: integer (nullable = true)
 |-- Parch: integer (nullable = true)
 |-- Ticket: string (nullable = true)
 |-- Fare: double (nullable = true)
 |-- Cabin: string (nullable = true)
 |-- Embarked: string (nullable = true)</code></pre></figure>

<p>The <em>Survived</em> column is the target column.</p>

<h3 id="12--handling-missing-values">1.2  Handling Missing Values</h3>
<p>In many data science cases, we need to handle missing values. These are the values which are not observed or not present due to issue in data capturing process.</p>

<p>In our dataset, <em>Age</em> of some of the passengers is not known. So we use <em>na.fill</em> API to fill the mean age for all the missing age values.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">meanValue</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">agg</span><span class="o">(</span><span class="nf">mean</span><span class="o">(</span><span class="nf">df</span><span class="o">(</span><span class="s">"Age"</span><span class="o">))).</span><span class="py">first</span><span class="o">.</span><span class="py">getDouble</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">fixedDf</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">na</span><span class="o">.</span><span class="py">fill</span><span class="o">(</span><span class="n">meanValue</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Age"</span><span class="o">))</span></code></pre></figure>

<h3 id="13-split-data-for-train-and-holdout">1.3 Split Data for Train and Holdout</h3>

<p>One we prepared our data, we split the data for training and hold out. We use spark’s <em>randomSplit</em> method to do the same.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">dfs</span> <span class="k">=</span> <span class="nv">fixedDf</span><span class="o">.</span><span class="py">randomSplit</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mf">0.7</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">trainDf</span> <span class="k">=</span> <span class="nf">dfs</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">withColumnRenamed</span><span class="o">(</span><span class="s">"Survived"</span><span class="o">,</span> <span class="s">"label"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">crossDf</span> <span class="k">=</span> <span class="nf">dfs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

<h3 id="14-handling-categorical-variables">1.4 Handling Categorical Variables</h3>

<p>In our dataset, many columns like <em>Sex</em>,<em>Embarked</em> are categorical variables. So we are one-hot encoding them using spark ML pipeline API’s.
In this example, we are using <em>StringIndexer</em> and <em>OneHotEncoder</em> to do that.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="nf">handleCategorical</span><span class="o">(</span><span class="n">column</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">PipelineStage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">stringIndexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StringIndexer</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="n">column</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="n">s</span><span class="s">"${column}_index"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setHandleInvalid</span><span class="o">(</span><span class="s">"skip"</span><span class="o">)</span>
  <span class="k">val</span> <span class="nv">oneHot</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">OneHotEncoder</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="n">s</span><span class="s">"${column}_index"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="n">s</span><span class="s">"${column}_onehot"</span><span class="o">)</span>
  <span class="nc">Array</span><span class="o">(</span><span class="n">stringIndexer</span><span class="o">,</span> <span class="n">oneHot</span><span class="o">)</span>
<span class="o">}</span></code></pre></figure>

<p>Create stages for all categorical variables</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"> <span class="k">val</span> <span class="nv">genderStages</span> <span class="k">=</span> <span class="nf">handleCategorical</span><span class="o">(</span><span class="s">"Sex"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">embarkedStages</span> <span class="k">=</span> <span class="nf">handleCategorical</span><span class="o">(</span><span class="s">"Embarked"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">pClassStages</span> <span class="k">=</span> <span class="nf">handleCategorical</span><span class="o">(</span><span class="s">"Pclass"</span><span class="o">)</span></code></pre></figure>

<h2 id="2-classification-using-randomforest">2. Classification using RandomForest</h2>

<p>Random Forest is one of the best algorithm for classification purposes. So we will using it for our problem.</p>

<h3 id="21-create-ml-pipeline-with-randomforest-classifier">2.1. Create ML Pipeline with RandomForest Classifier</h3>

<p>The below code creates a vector assembler stage which accumulates all the features we are using for our training. Then we create random forest
stage for classification.</p>

<p>Then finally we create a ML pipeline with all the stages.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">//columns for training</span>
<span class="k">val</span> <span class="nv">cols</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Sex_onehot"</span><span class="o">,</span> <span class="s">"Embarked_onehot"</span><span class="o">,</span> <span class="s">"Pclass_onehot"</span><span class="o">,</span> <span class="s">"SibSp"</span><span class="o">,</span> <span class="s">"Parch"</span><span class="o">,</span> <span class="s">"Age"</span><span class="o">,</span> <span class="s">"Fare"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">vectorAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="n">cols</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="c1">//algorithm stage</span>
<span class="k">val</span> <span class="nv">randomForestClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RandomForestClassifier</span><span class="o">()</span>
<span class="c1">//pipeline</span>
<span class="k">val</span> <span class="nv">preProcessStages</span> <span class="k">=</span> <span class="n">genderStages</span> <span class="o">++</span> <span class="n">embarkedStages</span> <span class="o">++</span> <span class="n">pClassStages</span> <span class="o">++</span> <span class="nc">Array</span><span class="o">(</span><span class="n">vectorAssembler</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="n">preProcessStages</span> <span class="o">++</span> <span class="nc">Array</span><span class="o">(</span><span class="n">randomForestClassifier</span><span class="o">))</span></code></pre></figure>

<h3 id="22-fit-the-model">2.2 Fit the model</h3>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainDf</span><span class="o">)</span></code></pre></figure>

<h3 id="23-accuracy-score">2.3. Accuracy Score</h3>

<p>Once model is trained, we need to know how it’s performing. So we use <em>accuracy score</em> as our evaluation metric. The below code shows how to calculate the same.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="nf">accuracyScore</span><span class="o">(</span><span class="n">df</span><span class="k">:</span> <span class="kt">DataFrame</span><span class="o">,</span> <span class="n">label</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">predictCol</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">rdd</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">predictCol</span><span class="o">).</span><span class="py">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">row</span> <span class="k">⇒</span> <span class="o">(</span><span class="nv">row</span><span class="o">.</span><span class="py">getInt</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">toDouble</span><span class="o">,</span> <span class="nv">row</span><span class="o">.</span><span class="py">getDouble</span><span class="o">(</span><span class="mi">1</span><span class="o">)))</span>
  <span class="k">new</span> <span class="nc">MulticlassMetrics</span><span class="o">(</span><span class="n">rdd</span><span class="o">).</span><span class="py">accuracy</span>
<span class="o">}</span>

  <span class="nf">println</span><span class="o">(</span><span class="s">"train accuracy with pipeline"</span> <span class="o">+</span> <span class="nf">accuracyScore</span><span class="o">(</span><span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">trainDf</span><span class="o">),</span> <span class="s">"label"</span><span class="o">,</span> <span class="s">"prediction"</span><span class="o">))</span>
  <span class="nf">println</span><span class="o">(</span><span class="s">"test accuracy with pipeline"</span> <span class="o">+</span> <span class="nf">accuracyScore</span><span class="o">(</span><span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">crossDf</span><span class="o">),</span> <span class="s">"Survived"</span><span class="o">,</span> <span class="s">"prediction"</span><span class="o">))</span></code></pre></figure>

<h3 id="24-results">2.4. Results</h3>

<p>The below are the results.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">train accuracy with pipeline0.8516746411483254
test accuracy with pipeline0.816793893129771</code></pre></figure>

<h2 id="3-cross-validation-and-hyper-parameter-tuning">3. Cross Validation and Hyper Parameter Tuning</h2>

<p>Random forest comes with many parameters which we can tune. Tuning them manually is lot of work. So we can use cross validation facility provided by spark ML to search through these parameter space to come up with best parameters for our data.</p>

<h3 id="31-specifying-the-parameter-grid">3.1. Specifying the parameter grid</h3>

<p>The below are the parameters which we want to search for.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">paramMap</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ParamGridBuilder</span><span class="o">()</span>
  <span class="o">.</span><span class="py">addGrid</span><span class="o">(</span><span class="nv">randomForestClassifier</span><span class="o">.</span><span class="py">impurity</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"gini"</span><span class="o">,</span> <span class="s">"entropy"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">addGrid</span><span class="o">(</span><span class="nv">randomForestClassifier</span><span class="o">.</span><span class="py">maxDepth</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">15</span><span class="o">))</span>
  <span class="o">.</span><span class="py">addGrid</span><span class="o">(</span><span class="nv">randomForestClassifier</span><span class="o">.</span><span class="py">minInstancesPerNode</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">10</span><span class="o">))</span>
  <span class="o">.</span><span class="py">build</span><span class="o">()</span></code></pre></figure>

<h3 id="32-cross-validation">3.2 Cross Validation</h3>

<p>Once we define the parameters, we define cross validation stage to search through these parameters. Cross validation also make sures that we don’t overfit the data.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="nf">crossValidation</span><span class="o">(</span><span class="n">pipeline</span><span class="k">:</span> <span class="kt">Pipeline</span><span class="o">,</span> <span class="n">paramMap</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">ParamMap</span><span class="o">],</span> <span class="n">df</span><span class="k">:</span> <span class="kt">DataFrame</span><span class="o">)</span><span class="k">:</span> <span class="kt">Model</span><span class="o">[</span><span class="k">_</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">cv</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CrossValidator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setEstimator</span><span class="o">(</span><span class="n">pipeline</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEvaluator</span><span class="o">(</span><span class="k">new</span> <span class="nc">BinaryClassificationEvaluator</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEstimatorParamMaps</span><span class="o">(</span><span class="n">paramMap</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNumFolds</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
  <span class="nv">cv</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="o">}</span>
<span class="k">val</span> <span class="nv">cvModel</span> <span class="k">=</span> <span class="nf">crossValidation</span><span class="o">(</span><span class="n">pipeline</span><span class="o">,</span> <span class="n">paramMap</span><span class="o">,</span> <span class="n">trainDf</span><span class="o">)</span></code></pre></figure>

<h3 id="33-results">3.3 Results</h3>

<p>As you can we got much better results using cross validation.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">train accuracy with cross validation0.8787878787878788
test accuracy with cross validation 0.8577099236641222</code></pre></figure>

<h2 id="4-generating-submit-file">4. Generating Submit File</h2>

<p>As the data used in this example is part of kaggle competition, I generated results for their test data to sumbit using below code.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"> <span class="k">val</span> <span class="nv">testDf</span> <span class="k">=</span> <span class="nv">sparkSession</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">option</span><span class="o">(</span><span class="s">"inferSchema"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/main/resources/titanic/test.csv"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">fareMeanValue</span> <span class="k">=</span> <span class="nv">df</span><span class="o">.</span><span class="py">agg</span><span class="o">(</span><span class="nf">mean</span><span class="o">(</span><span class="nf">df</span><span class="o">(</span><span class="s">"Fare"</span><span class="o">))).</span><span class="py">first</span><span class="o">.</span><span class="py">getDouble</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">fixedOutputDf</span> <span class="k">=</span> <span class="nv">testDf</span><span class="o">.</span><span class="py">na</span><span class="o">.</span><span class="py">fill</span><span class="o">(</span><span class="n">meanValue</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"age"</span><span class="o">)).</span><span class="py">na</span><span class="o">.</span><span class="py">fill</span><span class="o">(</span><span class="n">fareMeanValue</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Fare"</span><span class="o">))</span>                                                 </code></pre></figure>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala">  <span class="k">def</span> <span class="nf">generateOutputFile</span><span class="o">(</span><span class="n">testDF</span><span class="k">:</span> <span class="kt">DataFrame</span><span class="o">,</span> <span class="n">model</span><span class="k">:</span> <span class="kt">Model</span><span class="o">[</span><span class="k">_</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>                                                                                          <span class="k">val</span> <span class="nv">scoredDf</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">testDF</span><span class="o">)</span>
    <span class="k">val</span> <span class="nv">outputDf</span> <span class="k">=</span> <span class="nv">scoredDf</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"PassengerId"</span><span class="o">,</span> <span class="s">"prediction"</span><span class="o">)</span>
    <span class="k">val</span> <span class="nv">castedDf</span> <span class="k">=</span> <span class="nv">outputDf</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="nf">outputDf</span><span class="o">(</span><span class="s">"PassengerId"</span><span class="o">),</span> <span class="nf">outputDf</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">).</span><span class="py">cast</span><span class="o">(</span><span class="nc">IntegerType</span><span class="o">).</span><span class="py">as</span><span class="o">(</span><span class="s">"Survived"</span><span class="o">))</span>                                      <span class="nv">castedDf</span><span class="o">.</span><span class="py">write</span><span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"csv"</span><span class="o">).</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">mode</span><span class="o">(</span><span class="nv">SaveMode</span><span class="o">.</span><span class="py">Overwrite</span><span class="o">).</span><span class="py">save</span><span class="o">(</span><span class="s">"src/main/resources/output/"</span><span class="o">)</span>
  <span class="o">}</span></code></pre></figure>

<p>You can access complete code on  <a href="https://github.com/phatak-dev/spark-ml-kaggle/blob/master/src/main/scala/com/madhukaraphatak/spark/ml/titanic/RandomForest.scala">github</a>.</p>

<h2 id="kaggle-ranking">Kaggle Ranking</h2>

<p>Using the above code I got accuracy of <strong>0.81</strong> and <strong>250</strong> rank in kaggle.</p>


</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">17 Oct 2022</span>
     &raquo; <a href="/latest-java-4">Latest Java Features from a Scala Dev Perspective - Part 4: Higher Order Functions</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">10 Oct 2022</span>
     &raquo; <a href="/latest-java-3">Latest Java Features from a Scala Dev Perspective - Part 3: Functional Interfaces</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">14 Sep 2022</span>
     &raquo; <a href="/latest-java-2">Latest Java Features from a Scala Dev Perspective - Part 2: Lambda Expressions</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-2">Pandas API on Apache Spark - Part 2: Hello World</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-1">Pandas API on Apache Spark - Part 1: Introduction</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">11 Nov 2020</span>
     &raquo; <a href="/barrier-execution-mode-part-2">Barrier Execution Mode in Spark 3.0 - Part 2 : Barrier RDD</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>