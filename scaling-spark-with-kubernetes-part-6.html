<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Scalable Spark Deployment using Kubernetes - Part 6 : Building Spark 2.0 Two Node Cluster</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="http://blog.madhukaraphatak.com/scaling-spark-with-kubernetes-part-6">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Scalable Spark Deployment using Kubernetes - Part 6 : Building Spark 2.0 Two Node Cluster</h1>
  <p class="meta">Feb 26, 2017</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/kubernetes-series"><span class="category">kubernetes-series</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>In last post, we have built spark 2.0 docker image. As a next step we will be building two node spark standalone cluster using that image. In the context of of kubernetes,  node analogues to a container. So in the sixth blog of the series, we will be building two node cluster containing single master and single worker.You can access all the posts in the series <a href="/categories/kubernetes-series">here</a>.</p>

<p>TL;DR you can access all the source code on <a href="https://github.com/phatak-dev/kubernetes-spark">github</a>.</p>

<h3 id="spark-master-deployment">Spark Master Deployment</h3>

<p>To start with we define our master using kubernetes deployment abstraction. As you can recall from <a href="/scaling-spark-with-kubernetes-part-3">earlier</a> post, deployment abstraction is used for defining one or morepods. Even though we need single master in our cluster, we will use deployment abstraction over pod as it gives us more flexiblity.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">extensions/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">spark-master</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-master</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">spark-master</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name </span><span class="pi">:</span> <span class="s">spark-master</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">spark-2.1.0-bin-hadoop2.6</span> 
        <span class="na">imagePullPolicy</span><span class="pi">:</span> <span class="s2">"</span><span class="s">IfNotPresent"</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">spark-master</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">7077</span>
          <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
        <span class="na">command</span><span class="pi">:</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">/bin/bash"</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">-c"</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">--"</span>
        <span class="na">args </span><span class="pi">:</span>
         <span class="pi">-</span> <span class="s1">'</span><span class="s">./start-master.sh</span><span class="nv"> </span><span class="s">;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">infinity'</span></code></pre></figure>

<p>The above yaml configuration shows the configuration for the master. The noteworthy pieces are</p>

<ul>
  <li>
    <p>image - We are using the image we built in our last post. This is availble in local docker images.</p>
  </li>
  <li>
    <p>imagePullPolicy - By default kubernetes tries to pull the image from remote servers like dockerhub. But as our image is only available locally, we need to tell to kubernetes not to pull from remote. <em>imagePullPolicy</em> property of configuration allows to us to control that. In our example, we say <em>IfNotPresent</em> , which means pull only if there is no local copy. As we already have built the image, it will be avaialble and kubernetes will not try to pull from remote.</p>
  </li>
  <li>
    <p>ports - We are exposing port <em>7077</em> on which spark master will listen.</p>
  </li>
  <li>
    <p>command - Command is the configuration which tells what command to run when container bootstraps. Here we are specifying it to run <em>start-master</em> script</p>
  </li>
</ul>

<p>You can access complete configuration on <a href="https://github.com/phatak-dev/kubernetes-spark/blob/master/spark-master.yaml">github</a>.</p>

<h3 id="starting-spark-master">Starting Spark Master</h3>

<p>Once we have our configuration ready, we can start the spark master pod using below command</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">kubectl create <span class="nt">-f</span> spark-master.yaml </code></pre></figure>

<h3 id="spark-master-service">Spark Master Service</h3>

<p>Once we have defined and ran the spark master, next step is to define the service for spark master. This service exposes the spark master on network and other workers can connect to it.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-master</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">spark-master</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="c1"># the port that this service should serve on</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">webui</span>
    <span class="na">port</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">spark</span>
    <span class="na">port</span><span class="pi">:</span> <span class="m">7077</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="m">7077</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">spark-master</span></code></pre></figure>

<p>The above yaml configuration for spark master service. We are naming the our service also <em>spark-master</em> which helps in resolving proper hosts on cluster.</p>

<p>We are also exposing the additional port 8080 for accessing spark web ui.</p>

<p>You can access complete configuration on <a href="https://github.com/phatak-dev/kubernetes-spark/blob/master/spark-master-service.yaml">github</a>.</p>

<h3 id="starting-spark-master-service">Starting Spark Master Service</h3>

<p>Once we have defined the master service, we can now start the service using below command.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">kubectl create <span class="nt">-f</span> spark-master-service.yaml</code></pre></figure>

<h3 id="spark-worker-configuration">Spark Worker Configuration</h3>

<p>Once we have our spark master and it’s service started, we can define the worker configuration.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">extensions/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">spark-2.1.0-bin-hadoop2.6</span> 
        <span class="na">imagePullPolicy </span><span class="pi">:</span> <span class="s2">"</span><span class="s">IfNotPresent"</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">spark-worker</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">7078</span>
          <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
        <span class="na">command</span><span class="pi">:</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">/bin/bash"</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">-c"</span>
         <span class="pi">-</span> <span class="s2">"</span><span class="s">--"</span>
        <span class="na">args </span><span class="pi">:</span>
         <span class="pi">-</span> <span class="s1">'</span><span class="s">./start-worker.sh</span><span class="nv"> </span><span class="s">;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">infinity'</span></code></pre></figure>

<p>As we are building two node cluster, we will be running only single worker as of now. Most of the configuration are same as master other than command which starts the worker.</p>

<p>You can access complete configuration on <a href="https://github.com/phatak-dev/kubernetes-spark/blob/master/spark-worker.yaml">github</a>.</p>

<h3 id="starting-worker">Starting Worker</h3>

<p>You can start worker deployment using below command</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">kubectl create <span class="nt">-f</span> spark-worker.yaml</code></pre></figure>

<p>Now we have all services are ready</p>

<h3 id="verifying-the-setup">Verifying the Setup</h3>

<p>Run below command to verify that both spark master and spark worker deployments are started.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">kubectl get po </code></pre></figure>

<p>The above command should two pods running as below</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">NAME                            READY     STATUS    RESTARTS   AGE
spark-master-498980536-6ljcw    1/1       Running   0          15h
spark-worker-1887160080-nmpq5   1/1       Running   0          14h</code></pre></figure>

<p>Please note that exact name of the pod will differ from machine to machine.</p>

<p>Once we verified the pods, verify the service using below command</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">kubectl describe svc spark-master</code></pre></figure>

<p>The above command should show result as below</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">Name:                   spark-master
Namespace:              default
Labels:                 name=spark-master
Selector:               name=spark-master
Type:                   ClusterIP
IP:                     10.0.0.147
Port:                   webui   8080/TCP
Endpoints:              172.17.0.3:8080
Port:                   spark   7077/TCP
Endpoints:              172.17.0.3:7077
Session Affinity:       None</code></pre></figure>

<p>If both of the commands ran successfully, then we have spark cluster running successfully.</p>

<h3 id="testing-our-spark-cluster">Testing our spark cluster</h3>

<p>We can test our spark deployment using observing web ui and running some commands from spark shell.</p>

<h4 id="accessing-web-ui">Accessing Web UI</h4>

<p>In our configuration of spark master, we have exposed the UI port 8080. Normally it will be only available within spark cluster. But using the port forwarding, we can access the port on our local machine.</p>

<p>First let’s see the pods running on cluster using below command</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">kubectl get po</code></pre></figure>

<p>It should show the below result</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">NAME                           READY     STATUS    RESTARTS   AGE
spark-master-498980536-kfgg8   1/1       Running   0          14m
spark-worker-91608803-l22pw    1/1       Running   0          56s</code></pre></figure>

<p>We should port forward from master pod. Run below command. The exact name of the pod will differ from machine to machine.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh"> kubectl port-forward spark-master-498980536-kfgg8 8080:8080</code></pre></figure>

<p>Port-forward takes two parameters. One is the pod name and then port pair. In port pair the first port is container port and next one is local.</p>

<p>Once port is forwarded, go to this link <a href="http://localhost:8080">http://localhost:8080</a>.</p>

<p>You should see the below image</p>

<p><img src="/images/spark-ui-kube.png" alt="spark-ui-kube" /></p>

<h4 id="spark-shell">Spark Shell</h4>

<p>Once we have spark ui, we can test the spark from shell. Let’s run the spark shell from master container.</p>

<p>First we need to login to our master pod. Run below command</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">kubectl <span class="nb">exec</span> <span class="nt">-it</span> spark-master-498980536-kfgg8 bash</code></pre></figure>

<p>Start the spark shell using below command</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">/opt/spark/bin/spark-shell <span class="nt">--master</span> spark://spark-master:7077</code></pre></figure>

<p>Run below command to run some spark code</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nv">sc</span><span class="o">.</span><span class="py">makeRDD</span><span class="o">(</span><span class="nc">List</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">4</span><span class="o">)).</span><span class="py">count</span></code></pre></figure>

<p>If the code runs successfully, then our cluster setup is working.</p>

<h3 id="conclusion">Conclusion</h3>

<p>In this blog, we have succesfully built two node spark cluster using kubernetes absttractions.</p>

<h3 id="whats-next">What’s Next?</h3>

<p>Now we have defined our barebone cluster. In next blog, we will how to scale the cluster using kubernetes tools. Also we will discuss how to do resource management in the cluster.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">14 Sep 2022</span>
     &raquo; <a href="/latest-java-2">Latest Java Features from a Scala Dev Perspective - Part 2: Lambda Expressions</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">14 Sep 2022</span>
     &raquo; <a href="/latest-java-1">Latest Java Features from a Scala Dev Perspective - Part 1: Type Inference</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">02 Nov 2020</span>
     &raquo; <a href="/spark-3-introduction-part-10">Introduction to Spark 3.0 - Part 10 : Ignoring Data Locality in Spark</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-2">Pandas API on Apache Spark - Part 2: Hello World</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-1">Pandas API on Apache Spark - Part 1: Introduction</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">11 Nov 2020</span>
     &raquo; <a href="/barrier-execution-mode-part-2">Barrier Execution Mode in Spark 3.0 - Part 2 : Barrier RDD</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>