<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Exploring Spark DataSource V2 - Part 6  : Anatomy of V2 Write API</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/spark-datasource-v2-part-6">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Exploring Spark DataSource V2 - Part 6  : Anatomy of V2 Write API</h1>
  <p class="meta">Jun 7, 2018</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/datasource-v2-series"><span class="category">datasource-v2-series</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>In spark, data source is one of the foundational API for structured data analysis. Combined with dataframe and spark SQL abstractions, it makes spark one of the most complete structured data engine out there. You can read more about structured data analysis in spark <a href="/categories/datasource-series">here</a>.</p>

<p>Data source API was introduced in spark 1.3 along with dataframe abstraction. After that release, spark has undergone tremendous change. Spark has moved to custom memory management and with 2.0 we got Dataset , a better dataframe, abstraction. With these tremendous changes data source API needed to revisited.</p>

<p>So in 2.3 version, spark has released new version of data source API known as as data source V2. This API reflects all the learning spark developers learnt in last few releases. This API will be foundation for next few years of spark data source connectivity.</p>

<p>In this series of posts, I will be discussing about different parts of the API. We will be learning API by building data sources for different sources like flat file, relational databases etc.</p>

<p>This is sixth blog in the series where we discuss about different interfaces to write data in V2 API.You can read all the post in the series <a href="/categories/datasource-v2-series">here</a>.</p>

<h2 id="write-api--with-transactions">Write API  with Transactions</h2>

<p>One of the shortcoming of the data source V1 API was bare bone write API. It was not built to support complex down stream systems like databases. Also the interface has not exposed any transactional support. So it was all left to user to do all the complex handling of failures and cleanup.</p>

<p>Datasource V2 API addresses this shortcoming. It has transactional support in API level. This makes building more powerful connectors much easier.</p>

<h2 id="write-api-interfaces">Write API Interfaces</h2>

<p>Write API interfaces mimics the read interfaces which we saw in last few posts. The below are the different interfaces.</p>

<h2 id="datasourcev2">DataSourceV2</h2>

<p>DataSourceV2 is a marker interface. It doesn’t have any methods to override. Extending this interface we indicate that we are implementing support for V2 datasource.</p>

<h2 id="writersupport">WriterSupport</h2>

<p>WriterSupport is interface which indicates that data source supports write.</p>

<p>It has single method with below signature</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="nf">createWriter</span><span class="o">(</span><span class="n">jobId</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">schema</span><span class="k">:</span> <span class="kt">StructType</span><span class="o">,</span> <span class="n">mode</span><span class="k">:</span> <span class="kt">SaveMode</span><span class="o">,</span> 
<span class="n">options</span><span class="k">:</span> <span class="kt">DataSourceOptions</span><span class="o">)</span><span class="k">:</span> <span class="kt">Optional</span><span class="o">[</span><span class="kt">DataSourceWriter</span><span class="o">]</span></code></pre></figure>

<p>From the above signature it’s clear that,it’s an entry point method for data source. The below are different options</p>

<ul>
  <li>
    <p>jobId - Id of the job in which this write is happening.</p>
  </li>
  <li>
    <p>schema - Schema of DataFrame/Dataset that need to be written</p>
  </li>
  <li>
    <p>SaveMode - Different modes of write like overwrite, update etc. This is same as earlier API</p>
  </li>
  <li>
    <p>options - Map containing all the options passed to connect to the underneath source.</p>
  </li>
</ul>

<p>The method returns an optional <em>DataSourceWriter</em>. <em>Optional</em> type is a Java 8 equivalent of scala <em>Option</em>. The return type is optional here, because data source can decide not to do anything depending upon the <em>SaveMode</em>.</p>

<h2 id="datasourcewriter">DataSourceWriter</h2>

<p>DataSourceWriter is the primary interface for actually responsible for writing. It exposes below methods</p>

<ul>
  <li>
    <h3 id="datawriterfactory">DataWriterFactory</h3>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"> <span class="k">def</span> <span class="nf">createWriterFactory</span><span class="k">:</span><span class="kt">DataWriterFactory</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span></code></pre></figure>

<p>DataWriterFactory is a factory class to create actual data writers. For each partition of data it is created and sent to executors.</p>

<p>It’s little bit different compared to read path. In read, data source returned a list of factory objects. The reason for that is, the list indicated how many partitions needs to be created. But in case of write, spark already knows number of partitions. So no need to of list here.</p>

<ul>
  <li>
    <h3 id="commit">Commit</h3>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="nf">commit</span><span class="o">(</span><span class="n">messages</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">WriterCommitMessage</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span></code></pre></figure>

<p>As we discussed before, the above method is part of transaction support in the writer. When all the writing is done, this method is called to commit. This is overall commit. Individual partition commit will be there in DataWriter interface which we will discuss below.</p>

<p>WriterCommitMessage is a message interface, that should be used by data source to define their own messages to indicate the status of each partition write.</p>

<ul>
  <li>
    <h3 id="abort">Abort</h3>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="nf">abort</span><span class="o">(</span><span class="n">messages</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">WriterCommitMessage</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span></code></pre></figure>

<p>It’s a mirror interface to commit. This is called whenever there is complete failure of job. This is used to cleanup the partially written data.</p>

<h2 id="datawriterfactory-1">DataWriterFactory</h2>

<p>It’s a factory class to create actual data writer. This code executes in each executor.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"> <span class="k">def</span> <span class="nf">createDataWriter</span><span class="o">(</span><span class="n">partitionId</span><span class="k">:</span><span class="kt">Int</span><span class="o">,</span> <span class="n">attemptNumber</span><span class="k">:</span><span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">DataWriter</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span></code></pre></figure>

<p>As the name suggest, it creates data writers. The parameters are</p>

<ul>
  <li>
    <p>partitionId - Id of partition. This helps writer to understand which partition it’s writing</p>
  </li>
  <li>
    <p>attemptNumber - In case of writing, there can be multiple attempts. These attempts can be due to speculative run or because
of failures</p>
  </li>
</ul>

<p>Method returns DataWriter. As of now, T can be Row only.</p>

<h2 id="datawriter">DataWriter</h2>

<p>Finally we have the interface which actually writes data. The below are methods</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="nf">write</span><span class="o">(</span><span class="n">record</span><span class="k">:</span> <span class="kt">T</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span>

<span class="k">def</span> <span class="nf">commit</span><span class="o">()</span><span class="k">:</span> <span class="kt">WriterCommitMessage</span>

<span class="k">def</span> <span class="nf">abort</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span></code></pre></figure>

<p><em>write</em> method is the one which responsible for actual write. Other two methods are same as <em>DataSourceWriter</em> but now they work at the level of partition. These methods are responsible committing or handling write failures at partition level.</p>

<p>The <em>WriterCommitMessage</em> sent by commit method in this interface are the one which are sent to <em>DataSourceWriter</em>. This helps data source to understand status of each partition.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Datasource V2 brings transaction support to data source writes. This makes API more powerful and flexible.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">26 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-2">Understanding Spark Connect API - Part 2: Introduction to Architecture</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">09 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-1">Understanding Spark Connect API - Part 1: Shortcomings of Spark Driver Architecture</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">22 Jan 2023</span>
     &raquo; <a href="/latest-java-5">Latest Java Features from a Scala Dev Perspective - Part 5: Java Streams</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">26 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-2">Understanding Spark Connect API - Part 2: Introduction to Architecture</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">09 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-1">Understanding Spark Connect API - Part 1: Shortcomings of Spark Driver Architecture</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">21 Jul 2021</span>
     &raquo; <a href="/spark-pandas-part-2">Pandas API on Apache Spark - Part 2: Hello World</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>