<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Scalable Spark Deployment using Kubernetes - Part 5 : Building Spark 2.0 Docker Image</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Thoughts on technology, life and everything else.">
    <link rel="canonical" href="https://blog.madhukaraphatak.com/scaling-spark-with-kubernetes-part-5">
     <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/app.css">
       
</head>


    <body>

    <header >
  <div class="wrap">
    <a class="site-title" href="/">Madhukar's Blog</a>  
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">        
          <a class="page-link" href="http://www.madhukaraphatak.com">About me</a>                  
      </div>
    </nav>  
  </div>
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
 <header class="post-header">
  <h1>Scalable Spark Deployment using Kubernetes - Part 5 : Building Spark 2.0 Docker Image</h1>
  <p class="meta">Feb 26, 2017</p>
  <div class="catagories">
    
    <a href="/categories/scala"><span class="category">scala</span></a>
    
    <a href="/categories/spark"><span class="category">spark</span></a>
    
    <a href="/categories/kubernetes-series"><span class="category">kubernetes-series</span></a>
    
  </div>
</header> 

<article class="post-content">
  <p>In last few posts of our kubernetes series, we discussed about the various abstractions available in the framework. In next set of posts, we will be
building a spark cluster using those abstractions. As part of the cluster setup, we will discuss how to use various different configuration available
in kubernetes to achieve some of the import features of clustering. This is the fifth blog of the series, where we will discuss about building a spark
2.0 docker image for running spark stand alone cluster. You can access all the posts in the series <a href="/categories/kubernetes-series">here</a>.</p>

<p>TL;DR you can access all the source code on <a href="https://github.com/phatak-dev/kubernetes-spark">github</a>.</p>

<h3 id="need-for-custom-spark-image">Need for Custom Spark Image</h3>

<p>Kubernetes already has documented creating a spark cluster on <a href="https://github.com/kubernetes/kubernetes/tree/master/examples/spark">github</a>. But currently it uses old version of the spark. Also it has some configurations which are specific to google cloud. These configurations are not often needed in most of the use cases. So in this blog, we will developing a simple spark image which is based on kubernetes one.</p>

<p>This spark image is built for standalone spark clusters. From my personal experience, spark standalone mode is more suited for containerization
compared to yarn or mesos.</p>

<h3 id="docker-file">Docker File</h3>

<p>First step of creating a docker image is to write a docker file. In this section, we will discuss how to write a docker file needed
for spark.</p>

<p>The below are the different steps of docker file.</p>

<ul>
  <li>Base Image</li>
</ul>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">FROM java:openjdk-8-jdk</code></pre></figure>

<p>The above statement in the docker file defines the base image. We are using
a base image which gives us a debian kernel with java installed. We need 
java for all spark services.</p>

<ul>
  <li>Define Spark Version</li>
</ul>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">ENV spark_ver 2.1.0</code></pre></figure>

<p>The above line defines the version of spark. Using ENV, we can defines a variable and use it in different places in the script. Here we are building the spark with version 2.1.0. If you want other version, change this configuration.</p>

<ul>
  <li>Download and Install Spark Binary</li>
</ul>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">RUN <span class="nb">mkdir</span> <span class="nt">-p</span> /opt <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">cd</span> /opt <span class="o">&amp;&amp;</span> <span class="se">\</span>
    curl http://www.us.apache.org/dist/spark/spark-<span class="k">${</span><span class="nv">spark_ver</span><span class="k">}</span>/spark-<span class="k">${</span><span class="nv">spark_ver</span><span class="k">}</span><span class="nt">-bin-hadoop2</span>.6.tgz | <span class="se">\</span>
        <span class="nb">tar</span> <span class="nt">-zx</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">ln</span> <span class="nt">-s</span> spark-<span class="k">${</span><span class="nv">spark_ver</span><span class="k">}</span><span class="nt">-bin-hadoop2</span>.6 spark <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">echo </span>Spark <span class="k">${</span><span class="nv">spark_ver</span><span class="k">}</span> installed <span class="k">in</span> /opt</code></pre></figure>

<p>The above curl command and downloads the spark binary. It will be symlinked into /opt/spark.</p>

<ul>
  <li>Add start scripts to image</li>
</ul>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">ADD start-common.sh start-worker.sh start-master.sh /
RUN <span class="nb">chmod</span> +x /start-common.sh /start-master.sh /start-worker.sh</code></pre></figure>

<p>The above lines add some start scripts. We discuss more about these scripts
in next section.</p>

<p>Now we have our docker file ready. Save it as <em>Dockerfile</em>.</p>

<p>You can access the complete script on <a href="https://github.com/phatak-dev/kubernetes-spark/blob/master/docker/Dockerfile">github</a>.</p>

<h3 id="scripts">Scripts</h3>

<p>In above, we have added some scripts for starting master and worker. Let’s see what’s inside them.</p>

<ul>
  <li>start-common.sh</li>
</ul>

<p>This is a script which runs before starting master and worker.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c">#!/bin/bash</span>

<span class="nb">unset </span>SPARK_MASTER_PORT </code></pre></figure>

<p>The above script unsets a variable set by kubernetes. This is needed as this configuration interferes with the
spark clustering. We will discuss more about service variable in next post.</p>

<p>You can access complete script on <a href="https://github.com/phatak-dev/kubernetes-spark/blob/master/docker/start-common.sh">github</a>.</p>

<ul>
  <li>start-master.sh</li>
</ul>

<p>This is a script for starting master.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c">#!/bin/sh</span>

<span class="nb">.</span> /start-common.sh

<span class="nb">echo</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">hostname</span> <span class="nt">-i</span><span class="si">)</span><span class="s2"> spark-master"</span> <span class="o">&gt;&gt;</span> /etc/hosts

/opt/spark/sbin/start-master.sh <span class="nt">--ip</span> spark-master <span class="nt">--port</span> 7077</code></pre></figure>

<p>In the first step, we run the common script. We will be using <em>spark-master</em> as the host name for our master container. So we are adding that into <em>/etc/hosts</em> file.</p>

<p>Then we start the master using <em>start-master.sh</em> command. We will be listening on 7077 port for the master.</p>

<p>You can access complete script on <a href="https://github.com/phatak-dev/kubernetes-spark/blob/master/docker/start-master.sh">github</a>.</p>

<ul>
  <li>start-worker.sh</li>
</ul>

<p>This is the script for starting worker containers.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c">#!/bin/sh</span>

<span class="nb">.</span> /start-common.sh

/opt/spark/sbin/start-slave.sh spark://spark-master:7077</code></pre></figure>

<p>It is similar to master script. The only difference is we are using <em>start-slave.sh</em> for starting our worker nodes.</p>

<p>You can access complete script on <a href="https://github.com/phatak-dev/kubernetes-spark/blob/master/docker/start-worker.sh">github</a>.</p>

<p>Now we have our docker script ready. To build an image from the script, we need docker.</p>

<h3 id="installing-docker">Installing Docker</h3>

<p>You can install the docker on you machine using the steps <a href="https://docs.docker.com/engine/installation/">here</a>. I am using docker version <em>1.10.0</em>.</p>

<h3 id="using-kubernetes-docker-environment">Using Kubernetes Docker Environment</h3>

<p>Whenever we want to use docker, it normally runs a daemon on our machine. This daemon is used for building and pulling docker images. Even though we can build our docker image in our machine, it will be not that useful as our kubernetes runs in a vm. In this case, we need to push our docker image to vm and then only we can use the image in kubernetes.</p>

<p>Alternative to that, another approach is to use minikube docker daemon. In this way we can build the docker images directly on our virtual machine.</p>

<p>To access minikube docker daemon, run the below command</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nb">eval</span> <span class="si">$(</span>minikube docker-env<span class="si">)</span></code></pre></figure>

<p>Now you can run</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">docker ps </code></pre></figure>

<p>Now you can see all the kubernetes containers as docker containers. Now you have successfully connected to minikube docker environment.</p>

<h3 id="building-image">Building image</h3>

<p>Clone code from github as below</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh">git clone https://github.com/phatak-dev/kubernetes-spark.git</code></pre></figure>

<p>cd to <em>docker</em> folder then run the below docker command.</p>

<figure class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="nb">cd </span>docker

docker build <span class="nt">-t</span> spark-2.1.0-bin-hadoop2.6 .</code></pre></figure>

<p>In above command, we are tagging (naming) the image as <em>spark-2.1.0-bin-hadoop-2.6</em>.</p>

<p>Now our image is ready to deploy, spark 2.1.0 on kubernetes.</p>

<h3 id="conclusion">Conclusion</h3>

<p>In this post, we discussed how to build a spark 2.0 docker image from scratch. Having our own image gives more flexibility than using
off the shelf ones.</p>

<h3 id="whats-next">What’s Next?</h3>

<p>Now we have our spark image ready. In our next blog, we will discuss how to use this image to create a two node cluster in kubernetes.</p>

</article>
<div class="related">
  <h2>Related posts</h2>
  <ul>
    
             
    
    <li>    
     <span class="post-date">30 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-3">Understanding Spark Connect API - Part 3: Scala API Example</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">26 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-2">Understanding Spark Connect API - Part 2: Introduction to Architecture</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">09 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-1">Understanding Spark Connect API - Part 1: Shortcomings of Spark Driver Architecture</a>    
   </li>           
         

   
   
             
    
    <li>    
     <span class="post-date">30 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-3">Understanding Spark Connect API - Part 3: Scala API Example</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">26 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-2">Understanding Spark Connect API - Part 2: Introduction to Architecture</a>    
   </li>           
         

            
    
    <li>    
     <span class="post-date">09 May 2023</span>
     &raquo; <a href="/understanding-spark-connect-1">Understanding Spark Connect API - Part 1: Shortcomings of Spark Driver Architecture</a>    
   </li>           
         

   
   
 </ul>


 
<!--   
</div> -->

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">   
    <div class="footer-col-1 column">
      <ul>
        <li>
          <a href="https://github.com/phatak-dev">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">phatak-dev</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/madhukaraphatak">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">madhukaraphatak</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Thoughts on technology, life and everything else.</p>
    </div>

    <div style="float:right;">
      <a href="/feed.xml"><img src="/images/rss.png">
    </div>



  </div>

</footer>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52311191-1', 'auto');
  ga('send', 'pageview');

</script>

    </body>
</html>